<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[sqlalchemy框架下的数据库关系]]></title>
    <url>%2F2018%2F02%2F13%2Fsqlalchemy%E6%A1%86%E6%9E%B6%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[关系型数据库中表的关系一对多考虑下面的代码12345678910111213141516171819202122232425from flask-sqlalchemy import SQLAlchemyfrom flask import Flaskimport osapp = Flask(__name__)# 配置app，实例化SQLAlchemybasedir = os.path.abspath(os.path.dirname(__file__))app.config[&apos;SQLALCHEMY_DATABASE_URI&apos;] = &apos;sqlite:///&apos; + os.path.join(basedir + &apos;db.sqlite&apos;)app.config[&apos;SECRECT_KEY&apos;] = &apos;a secrect string&apos;db = SQLAlchemy(app)# 定义模型class Writer(db.model): __tablename__ = writers id = db.Column(db.Integer,primary_key=True) name = db.Column(db.String(64),unique=True) posts = db.relationship(&apos;articles&apos;,backref=&apos;writer&apos;)class Article(db.model): __tablename__ = articles id = db.Column(db.Integer,primary_key) title = db.Column(db.String(64)) body = db.Column(db.String(2018)) writer_id = db.Colum(db.Integer,ForeignKey=&apos;writers.id&apos;) 在Writer模型中，relationship定义了两张表之间的关系.relationship的backref属性相当于在另一张表中也定义了一个相关关系。这样Writer实例通过posts属性可以访问所有与之相关的Article模型，返回一个关联Article组成的列表。Article实例通过writer属性可以访问对应的Writer模型。 在Article模型中，writer_id属性被定义为外键，其值通过ForeignKey指向Writer模型中的主键。实例化模型123susan = writer(name=susan)love_python = article(title=&apos;love python&apos;,body=&apos;python is easy and \elegant&apos;,writer=susan) 在实例化Article模型时，由relationship反向定义的writer属性要传入与love_python对应的的Writer实例susan。这样就可以让love_python与susan两个实例关联起来。 一对一要让两张表是一对一关系，只需要在relationship中将uselist设为False。 多对一与一对多类似，只需要对调两张表。]]></content>
      <categories>
        <category>python 数据库</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python杂谈]]></title>
    <url>%2F2018%2F02%2F07%2Fpython%E6%9D%82%E8%B0%88%2F</url>
    <content type="text"><![CDATA[面向对象编程之方法与函数面向对象编程思想中，方法是指一个对象可以使用的功能，举个例子12arr = [1,2,3]arr.remove(2) arr被定义为指向列表对象的变量，而remove则是列表对象的一个方法，用于从列表中删除某个值。而函数则是对对象进行操作，例如12arr = [1,2,3]len(arr) len()函数对其参数求长度。在本例中len()的参数既是一个列表。 python常用的装饰器python中的装饰器可以对函数进行扩展。 @property@property装饰器可以把类的方法变成属性。例如1234567class Student(): def __init__(self,score): self.score = score#调用Student类qiuyue = Student(90)print(qiuyue.score) #输出结果90 可是这样也不无问题，比如当输入分数不合理（如1000）时，无法对分数进行检查。当然，可以对Student类附加方法实现检查分数。123456789101112131415class Student(): def get_score(self): return self._score def set_score(self,value): if not isinstance(score,int): raise ValueError(&apos;score must is an integer!&apos;) if value &gt; 100 or value &lt; 0: raise ValueError(&apos;score must between 0 to 100!&apos;) self._score = value#调用Student类qiuyue = Student()qiuyue.set_score(90)print(qiuyue.get_score()) #输出90 通过set方法对Student的score属性赋值，再用get方法获取score属性。这样就可以实现对score合法性的检查。但是为了一个属性特地写两个方法未免过于繁琐。所以用到装饰器@property封装set方法和get方法，实现对score属性赋值的同时进行数值合法性检查。 12345678910111213141516171819202122232425262728293031class Student(): @property def score(self) return self._score @score.setter def score(self,value) if not isinstance(value,int): raise ValueError(&apos;score must is an integer!&apos;) if value &gt; 100 or value &lt; 0: raise ValueError(&apos;score must between 0 to 100!&apos;) self._score = value @property def grade(self): if self._score is None: return None elif self._score &gt;= 90: print(&apos;优秀！&apos;) elif self._score &gt;=60: print(&apos;及格！) else: print(&apos;不及格！&apos;)#调用Student类qiuyue = Student()qiuyue.score = 90print(qiuyue.score) # 输出90qiuyue.score = 1000 # 报错，ValueErrorqiuyue.grade = &apos;及格&apos; # 报错qiuyue.grade # 输出优秀 可以看到，@property装饰的第一个score，实际上是一个get方法，而@score.setter装饰的第二个score实际上是set方法。@score.setter其实是@property装饰器的副产品。这两个装饰器一个装饰get方法，一个装饰set方法，这样就使score方法变成了Student类的属性，在对score属性赋值（即set方法）时会自动对值的合法性进行检查，调用score属性即调用get方法。@grade.setter并不是必须的，当缺少@grade.setter装饰器时grade属性变成只读属性，无法对其进行赋值，只能读取。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫之爬取静态网页(知识储备篇)]]></title>
    <url>%2F2018%2F01%2F29%2Fpython%E7%88%AC%E8%99%AB%E4%B9%8B%E7%88%AC%E5%8F%96%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[断断续续地学习爬虫也有一段时间了。最近接到点石的通知在寒假会开始Web后端方向的学习，趁着这几天有空抓紧把已经学会的知识整理一下。 HTTP相关知识客户端与服务器之间通过TCP/IP等协议进行HTTP报文的传输。HTTP报文又分为请求报文（客户端发送至服务器）和响应报文（服务器发送至客户端）。无论是哪种报文，其格式都是大同小异的。下面进行通过《图解HTTP》上的一张图片进行简单介绍上图分别是一个请求报文和一个响应报文。请求报文又分成两部分：请求头（GET/HTTP/1.1）和请求首部（XXXX:XXXX）。get是一种请求方法，表示请求从服务器获得信息，除此之外还有post方法（从服务器获得信息的同时向服务器传递一些信息），put方法（向服务器传递信息），delect方法（从服务器删除信息）等。HTTP/1.1表示该请求使用的是1.1版本的HTTP协议。而首部字段则包含了本次请求的有关信息，如Host表示本次请求的主机地址，User-Agent表示发出请求的浏览器内核信息，Accept-luangage表示浏览器接受的语言等。响应报文的响应头是HTTP/1.1 200 OK。200是一种状态码，表示成功，4xx表示客户端错误，5xx表示服务器错误，3xx表示重定向。响应首部字段内容与请求首部作业相同，报文主体里则包含了本次响应的具体信息，通常是HTML文档。更多有关http知识可以看《图解http》这本书，有大量的图例，内容较为浅显，适合新手入门。 requests库相关知识requests库是python爬虫常用库,常用于下载网页的html代码。使用上相比urllib要方便快捷得多。可以从官方文档获取有关这个库的详细使用方法requests文档 BeautifulSoup库相关知识BeautifulSoup库常用于解析下载好的HTML，通常与requests库配合使用。可以通过官方文档学习有关知识BeautifulSoup文档值得一提的是其自带了html_parser解析器，也可以在cmd下通过 pip isntall lxml 安装lxml解析器，由于lxml是用C写的，所以解析速度比html_parser快，但是用lxml作为解析器有时候会出现解析出来的HTML文档部分丢失的情况。 HTML相关知识HTML是网页的骨架，js，css都要有在HTML的基础才能进行开发。即使是Web后端也要对HTML有简单的认识。对于这部分的知识可以去W3school进行学习，里面还有关于JavaScript的教程，也是知识体系中很重要的一环，可以一并学习。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程与线程]]></title>
    <url>%2F2018%2F01%2F09%2F%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[开进程需要时间学习《python爬虫开发与项目实践》时，执行下面一段代码：1234567891011121314from multiprocessing import Processimport osdef run_process(name): print(&quot;Child process %s (%s) is running&quot; % (name,os.getpid()))if __name__ == &quot;__main__&quot;: print(&quot;parant process %s &quot; % os.getpid()) for i in range(5): p = Process(target=run_process, args=(str(i),)) print(&quot;process will start&quot;) p.start() p.join() print(&quot;process end&quot;) 显示的结果是123456789101112parant process 6332 process will startprocess will startprocess will startprocess will startprocess will startChild process 2 (9896) is runningChild process 0 (11208) is runningChild process 3 (5464) is runningChild process 1 (10208) is runningChild process 4 (12596) is runningprocess end 可以看到，程序在执行完1print (&quot;parant process %s &quot; % os.getpid()) 没有接着马上执行run_process()，而是先打印process will start，最后把子进程一起执行。这是因为子进程的创建是需要时间的，在这个空闲时间里父进程继续执行代码，而子进程在创建完成后显示。 Pool线程池需要创建多个进程时，可以使用multiprocessing中的Pool类开进程池。Pool()默认开启数量等于当前cpu核心数的子进程（当然可以手动改变）1234567891011121314from multiprocessing import Pooldef hello(i): print(&quot;hello ,this is the %d process&quot; % i)def main(): p = Pool() for i in range(1,5): p.apply_async(targe=hell0,args=(i,)) p.close p.joinif __name__ == &quot;__main__&quot;: main() apply_async表示在开线程时不阻塞主线程，是异步IO的一种方式之一。targe传入要在子线程中执行的函数（约定此时函数不用带括号），args以元组的方式传入函数的参数。join会等待线程池中的每一个线程执行完毕，在调用join之前必须要先调用close，close表示不能再向线程池中添加新的process了。 守护线程线程并没有主次的概念，我们一般说的‘主线程’实际上是main函数的线程，而所谓主线程结束子线程也会结束是因为在主线程结束时调用了退出函数。而守护线程是指‘不重要线程’。主线程会等所有‘重要’线程结束后才结束。通常当客户端访问服务器时会为这次访问开启一个守护线程。将setDaemon属性设为True即可将该线程设为守护线程。123456789101112from threading import Threadfrom multiprocessing import Processn = 100def count(x,y): n=x+yif __name__ == &apos;__main__&apos;: t = Thread(target=count,args=(1,2)) t.setDaemon = True]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http学习]]></title>
    <url>%2F2017%2F12%2F17%2Fhttp%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[TCP/IP与DNS什么是TCP/IP?协议中存在各式各样的内容。从电缆的规格到 IP 地址的选定方法、寻找异地用户的方法、双方建立通信的顺序，以及 Web 页面显示需要处理的步骤，等等。像这样把与互联网相关联的协议集合起来总称为 TCP/IP。HTTP 属于它内部的一个子集。也有说法认为，TCP/IP 是指 TCP 和 IP 这两种协议。还有一种说法认为，TCP/IP 是在 IP 协议的通信过程中，使用到的协议族的统称。 IPIP与IP地址不同。IP是一种网络协议，它的作用是把数据包传给对方。具体是通过MAC地址和ip地址来实现的。MAC地址对应网卡所属的固定地址，ip地址指节点被分配到的地址。IP地址可以与MAC地址对应，IP地址可以换，MAC地址一般是固定的。IP 间的通信依赖 MAC 地址。在网络上，通信的双方在同一局域网（LAN）内的情况是很少的，通常是经过多台计算机和网络设备中转才能连接到对方。而在进行中转时，会利用下一站中转设备的 MAC 地址来搜索下一个中转目标。这时，会采用 ARP 协议（AddressResolution Protocol）。ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC 地址。 TCP所谓的字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。而可靠的传输服务是指，能够把数据准确可靠地传给对方。一言以蔽之，TCP 协议为了更容易传送大数据才把数据分割，而且 TCP 协议能够确认数据最终是否送达到对方。 TCP的三次握手TCP把数据包发出去之后还会确认数据到达了目的地，通过三次握手机制进行确认。发送端发送数据时，TCP会向服务器发送带有SYN标记的数据包，当服务器接收到这个数据包后，会返回一个带有SYN或者ASK的数据包表示确认，最后发送端会再次发送带有ASK标志的数据包表示握手结束。 DNSDNS（Domain Name System）服务是和 HTTP 协议一样位于应用层的协议。它提供域名到 IP 地址之间的解析服务。计算机既可以被赋予 IP 地址，也可以被赋予主机名和域名。比如 www.baidu.com。用户通常使用主机名或域名来访问对方的计算机，而不是直接通过 IP 地址访问。因为与 IP 地址的一组纯数字相比，用字母配合数字的表示形式来指定计算机名更符合人类的记忆习惯。但要让计算机去理解名称，相对而言就变得困难了。因为计算机更擅长处理一长串数字。为了解决上述的问题，DNS 服务应运而生。DNS 协议提供通过域名查找 IP 地址，或逆向从 IP 地址反查域名的服务。 综上，从输入网址到服务器获得请求的过程是：]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新开始]]></title>
    <url>%2F2017%2F12%2F02%2F%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[前阵子手贱删了博客文件，还糊里糊涂地把coding里的项目也删了。然后各种蜜汁错误，各种无法重新部署。最近几天又蜜汁部署成功。可以说十分难受了。 不过塞翁失马，焉知非福。经过这么一遭我再次练习了一遍coding+hexo下博客的部署，也算是好事一桩了吧？（强行自我安慰一波233）以后我一定天天向上，重新做人，再不手贱。 再次感谢王哥的教程，很详细，帮助很大，很好，很棒。感兴趣的同志可以去他那里转转呀（手动滑稽）windliang的博客扯到这里算是暂时结束，以后有时间再上来扯扯淡，写点学习心得啥的吧。]]></content>
      <categories>
        <category>心得</category>
      </categories>
      <tags>
        <tag>闲聊</tag>
      </tags>
  </entry>
</search>
