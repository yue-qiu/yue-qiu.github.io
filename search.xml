<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flask-SQLAlchemy]]></title>
    <url>%2F2018%2F05%2F24%2FFlask-SQLAlchemy%2F</url>
    <content type="text"><![CDATA[两种初始化Flask-SQLAlchemy的方式先给出SQLAlchemy的参数： flask.ext.sqlalchemy.SQLAlchemy(app=None, use_native_unicode=True, session_options=None, metadata=None, query_class=&lt;class &#39;flask_sqlalchemy.BaseQuery&#39;&gt;, model_class=&lt;class &#39;flask_sqlalchemy.Model&#39;&gt;) 有两种方式可以初始化Flask-SQLAlchemy对象：立即使用或根据需要添加Flask应用程序：123456789101112131415from flask import Flaskfrom flask_sqlalchemy import SQLAlchemy"""以下两种方法都可以"""# 方法一：直接给SQLAlchemy传递app实例app = Flask(__name__)db = SQLAlchemy(app)# 方法二：创建对象，在稍后的配置工厂函数里支持它db = SQLAlchemy()def create_app(): app = Flask(__name__) db.init_app(app) ... 这两种方式的区别在于：第一种方式的create_all()和drop_all()总是可用的，而第二种方法只有当flask.Flask.app_context()存在时才可以用create_all()和drop_all()。 实例对象一旦创建，这个对象会包含sqlalchemy和sqlalchemy.orm中的所有函数和助手。此外，它还提供了一个名为 Model 的类，用于作为声明模型时的delarative基类 要创建表，可以在shell中导入db实例然后调用create_all()方法：12&gt;&gt;&gt; from app import db&gt;&gt;&gt; db.create_all() 这里要注意，此处的python shell必须已经把db相关的model导入context中，否则缺少相关模型create_all()不会成功。原因前面已经解释过了。 解决方法有两个： 每次启动shell时将db与app这两个Flask运行相关的运行context加载到shell上下文。 123456789101112131415161718from flask_script import Manager, shellfrom flask_sqlalchemy import SLQAlchemyfrom app import create_app, dbapp = create_app('Develop')app.config['SECRET_KEY'] = 'a secret string'app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql://username:password@hostname:port/databasename'manager = Manager(app)@app.shell_context_processordef make_shell_context(): return dict(app=current_app, db=db)manager.add_command("shell", Shell(make_context=make_shell_context))if __name__ == '__main__': manage.run() 在manage文件里导入相关db模型，然后flask-script添加一个创建数据表的命令 1234567891011121314151617# 导入所有db模型from modle import *from flask_sqlalchemy import SLQAlchemyfrom app import create_app, dbapp = create_app('Develop')app.config['SECRET_KEY'] = 'a secret string'app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql://username:password@hostname:port/databasename'manager = Manager(app)@manager.add_commanddef create_all(): db.create_all()if __name__ == '__main__': manage.run() 查询方法对于一个BaseQuery类，SQLAlchemy提供了一些查询方法用于获得你想要的查询对象。 all() 会以列表的形式返回所有的查询结果。 order_by(field[,DESC]) 根据某个字段进行排序，然后返回所有结果。默认按升序排列，如果添加DESC参数则以降序排列 limit(num) 限制返回查询结果的数量 offset(num) 根据偏移量返回查询结果。如：总共查询到10个人，偏移量是2，那么就只返回后8个人。 first() 返回第一个查询结果 first_or_404() 返回第一个查询结果，如果不存在就抛出404错误 get(ident) 通过主键查询 get_or_404(ident) 通过主键查询，如果不存在就抛出404错误 paginate(page=None, per_page=None, error_out=True)。page指定当前页数，per_page指定每一页有多少查询对象，error_out如果设为True，当请求的页数超出了范围时会抛出404错误。 paginate方法返回的是一个pagination类对象。这个类在Flask-SQLAlchemy中定义，这个对象包含很多属性，用于在模板中生成分页链接，下面介绍几个常用属性： items 当前页面中的记录 page 当前页数 prev_num 上一页的页数 next_num 下一页的页数 has_next 如果有下一页返回True has_prev 如果有上一页返回True pages 查询得到的总页数 per_page 每页显示的记录数量 total 查询返回的记录总数 在pagination类对象上还可以调用一些方法： prev(error_out=False) 上一页的分类对象 next(error_out=False) 下一页的分类对象 iter_pages(left_edge=2, left_current=2, right_current=5, right_edge=2) 一个迭代器。返回一个在分页导航中显示的页数列表。这个列表的最左边显示left_edge页，最右边显示right_edge页。当前页的左边显示left_current页，右边显示right_current页。如一个100页的列表中，当前页为第50页。则pagination.iter_pages()返回的列表为[1, 2, None, 48, 49, 50, 51, 52, 53, 54, 55, None, 99, 100]。None表示页数之间的间隔。关系型数据库中表的关系一对多考虑下面的代码12345678910111213# 定义模型class Writer(db.Model): __tablename__ = writers id = db.Column(db.Integer,primary_key=True) name = db.Column(db.String(64),unique=True) posts = db.relationship('Article',backref='writer')class Article(db.Model): __tablename__ = articles id = db.Column(db.Integer,primary_key) title = db.Column(db.String(64)) body = db.Column(db.String(2018)) writer_id = db.Colum(db.Integer,db.ForeignKey('writers.id')) 在Writer模型中，relationship()定义了两张表之间的关系：第一个参数是子表模型名，backref属性相当于在另一张表中也定义了一个相关关系，用于访问父表的模型。这样Writer实例通过posts属性可以访问所有与之相关的Article模型，返回一个关联Article组成的列表。Article实例通过writer属性可以访问对应的Writer模型。 在Article模型中，writer_id属性被定义为外键，ForeignKey()函数的含义是其所在的列的值域应当被限制在另一个表的指定列的取值范围之内。这里要说明:ForeignKey()函数的参数形式应为’表名.字段名’而不是’Model名.字段名’ 一对多关系中，在父表模型中定义db.relationship(),用于指出和子表的关系，在子表模型中定义db.ForeignKey指向父表。 如下例,在实例化Article模型时，由relationship反向定义的writer属性要传入与love_python对应的的Writer实例susan。这样就可以让love_python与susan两个实例关联起来。12susan = Writer(name=susan)love_python = Article(title='love python',body='python is easy and elegant'，writer=susan) 关系型数据库是通过主键与外键确定两张表的关系的。比如12345678w1 = Writer('Jack')w2 = Writer('Mike')a = Article('hello','world',writer=w1)、b = Article('hi','i like python',writer=w1)c = Article('haha','i like flask',writer=w2)db.session.add_all([w1,w2,a,b,c])db.session.commit()print(w.posts) # 会访问a和b，而不访问c 当w查询posts时，sqlalchemy会从Article模型中寻找外键与w.id相同的实例并返回这些对象。 多对一多对一关系中模型的定义与一对多类似，但是要将ForeignKey定义在父表中，即多的一方。123456789101112class Writer(db.Model): __tablename__ = writers id = db.Column(db.Integer,primary_key=True) name = db.Column(db.String(64),unique=True) article_id = db.Column(db.Integer,db.ForeignKey(articles.id) posts = db.relationship('Article',backref='writer')class Article(db.model): __tablename__ = articles id = db.Column(db.Integer,primary_key=True) title = db.Column(db.String(64)) body = db.Column(db.String(2018)) 一对一要让两张表是一对一关系，定义模型方式类似于一对多。只需要在一的模型中其relationship()的uselist参数设为False。对于多对一关系，要改成一对一关系也很简单，只要用backref()函数在一的一方定义一个关系，并且将urslist设为False即可。123456class Writer(db.Model): __tablename__ = writers id = db.Column(db.Integer,primary_key=True) name = db.Column(db.String(64),unique=True) article_id = db.Column(db.Integer,db.ForeignKey(articles.id) posts = db.relationship('Article',backref=db.backref('writer',uselist=False) 多对多要定义两张表的多对多关系，这时候光用两张表就不够了。要引入第三张表。举个例子，现在要定义课程与学生之间的关系。由于一个课程对应多个学生，一个学生也对应对个课程，这时候就不再是简单的一对多或者多对一而是多对多关系了。为了解决这个问题，我们引入第三张表Reflection，这张表定义了学生的id，对应的课程id与学生选这门课程的时间。这样一来，如果我们想要知道小明选了什么课，只需要在Reflection中根据小明的id找出对应的课程id，再通过课程id在Class中找到对应课程就OK啦~同时，通过Reflection我们还可以知道小明在什么时候选了这门课。12345678910111213141516171819class Reflection(db.Model): __tablename__ = 'reflections' id = db.Column(db.Integer,primary_key=True) student_id = db.Column(db.Integer,db.ForeignKey('students.id')) class_id = db.Column(db.Integer,db.ForeignKey('classes.id')) timestamp = db.Column(db.DateTime,default=datetime.utcnow)class Student(db.Model): __tablename__ = 'students' id = db.Column(db.Integer,primary_key=True) name = db.Column(db.String(64)) age = db.Column(db.Integer) classes = db.relationship('Reflection',backref=db.backref('students',lazy='joined'),lazy='dynamic')class Class(db.Model): __tablename__ = 'classes' id = db.Column(db.Integer,primary_key=True) name = db.Column(db.String(64)) student = db.relationship('Reflection',backref=db.backref('classes',lazy='joined'),lazy='dynamic') 值得一提的是，在定义Reflection中回引模型的属性时用了backref()方法，并且将回引属性定义为joined加载。joined加载会在调用Reflection的同时找出对应的Student模型和Class模型，换言之，此时Reflection中的student和class直接指向对应的实例。这样就避免了selected加载导致的仅在调用Reflection.student或Reflection.class才加载相应模型。因为从数据库中加载模型是很耗费时间的，用joined一次就把所有模型都调用出来了，而selected需要调用多次，换言之，这样提高了效率。定义好的模型的关系，我们就可以试着进行操作了：先创建学生和课程实例12345Mike = Student(name='Mike',age=18)English = Class(name='English')db.session.add(Mike)db.session.add(English)db.session.commit() 将学生与课程之间的关系添加到Reflection中123f = Reflection(students=Mike,classes=English)db.session.add(f)db.session.commit() 当我们想要查询学生的课程时，通过Student.classes获取到Reflection对象，再通过Reflection.class就可以查到该学生的课了。12student = Student.query.filter_by(name='Mike').first()classes = student.classes.class.all() 联结查询在上面的例子中，我们为了获取学生的课程，执行了多次查询，这样的效率太低了，最好是一次就直接把结果查询出来。我们可以考虑把Class和Reflection结合起来，然后分别过滤Reflection中student_id与class_id，这样就得到一张包含了学生和相应课程的表。这种操作就叫做联结查询。12345class Student(db.Model): ...... @property def getclass(self): return Reflection.query.join(Class,Class.id==Reflection.class_id).filter(Reflection.student_id==self.id) 下面对这行代码进行分析： Reflection.query返回Reflection对象 join(Class,Class.id==Reflection.class_id) 联结Class与Reflection表，并且将Class.id与Reflection.class_id的值对应起来，相当于sql语句中的on filter(Reflection.student_id==self.id) 对这张临时表进行过滤：只有Reflection.student_id与当前学生实例id相同的会留下来 这样，我们就可以使用这样临时的表来获取想要的内容了。]]></content>
      <categories>
        <category>Web开发</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串编码]]></title>
    <url>%2F2018%2F05%2F23%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[不同的编码方式由于计算机是美国人发明的，所以最早的时候只收录了127个字符，包括阿拉伯数字、英文字母大小写和一些常用符号，称为ASCII编码。后来计算机越来越普及，127个字符显然不够。于是各国又制定了自己国家的字符编码。为了避免不同国家之间通信出现乱码的问题，一种同一编码unicode编码诞生了。ASCII用一个字节（byte）来储存一个字符，而unicode用2到6个字节来储存字符，理论上所有的文字、符号都可以用unicode编码表示。 但是新的问题又出现了：unicode编码至少会用两个字节来表示一个字符，但是对于一些简单字符如A，@，这样做显然太浪费了，特别是文章中大量使用这种简单字符的时候。一种”可变长编码“应运而生：UTC-8编码。在UTC-8编码中，会为每个字符分配合适的字节数。这样就大大节约了空间，特别适合用于网络传输。在计算机内存中，同一使用unicode，而在网络传输和硬盘保存时，则将unicode转为UTF-8以节省空间。 字符与字节在python3中，字符默认以unicode方式编码，而在进行网络传输和硬盘保存时，常常将unicode字符串转成utf-8字节。这就要用到encode()方法：123s = 'hello world'with open('test', 'w') as f: f.write(s.encode('utf-8')) encode()将字符串转换成字节，而utf-8则指定是以何种编码格式转换。 当我们从网络上获取数据时，常常也是获取到以UTF-8形式编码的字节，为了方便我们对数据进行处理，用decode()方法：12b = b'\xe4\xb8\xad\xe6\x96\x87'print(b.decode('utf-8')) # 输出：'中文' 参数utf-8表明将字节以UTF-8的形式解码。在python中，字节的前面会有个前缀b。 为了避免乱码，应该始终坚持以UTF-8的形式进行字符和字节之间的转换。]]></content>
      <categories>
        <category>Web开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[unittest单元测试]]></title>
    <url>%2F2018%2F05%2F23%2Funittest%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[有个词叫TDD(Tset Driven Development)，测试驱动开发。一个好的开发人员不仅要懂开发，还要懂得一定的测试技巧。python自带了很多的测试库，比如unittest，coverage….介绍一下unittest的使用。 unittests四个重要的概念unittest有四个重要的面向对象概念： test fixture。这个概念主要处理测试环境的搭建和清理。很多时候我们在进行测试的时候需要搭建合适的环境，例如创建目录、创建数据库等，而在测试完毕后这些环境又不再需要了。test fixturn可以帮我们很好的处理这些事情。 test case。 既然要进行测试，测试用例当然是最重要的。每一项测试内容都是一个test case。 test suite。我们当然不希望只能一项项的进行测试，最好是将要测试的项目放在一起。test suite相当于test case的集合，当然test suite也能嵌套在test suite中。 test runner。顾名思义，这个概念负责执行测试并控制结果输出。 创建testcaseunittest提供了TastCase类，要创建一个testcase只需要继承这个父类就好了。 先在mathfunc.py编写三个函数用于测试：12345678def add(x, y): return x + ydef minus(x, y): return x - ydef string(s): return s 在test_math.py中创建测试用例：123456789101112131415from mathfunc import *from unittest import TestCaseclass TestMath(TestCase): def test_add(self): """测试add函数""" self.assertTrue(1+2, add(1, 2)) def test_minus(self): """测试minus函数""" self.assertEqual(2-1, minus(2, 1)) def test_string(self): """测试string函数""" self.assertIn('h' in string('hello')) 这就创建了一个testcase，包含三个测试。testcase中所有的测试必须以test开头。self.assert*()是由TestCase提供的测试函数。每一个测试里的文档会在输出测试报告时显示。不用python内置的assert()是因为uniittest在遇到self.assert*()发生错误时会把这个测试标记为failure，然后继续执行其他测试。 创建testsuite有了testcase，自然想把它加入到suite中。unittest提供了TestSuite类来表示一个suite。默认情况下，unittest按测试函数的函数名进行排序，然后按这个排序执行测试。如果我们想控制测试执行顺序，就要在向suite添加case时做点文章：123456789from mathfunc import *import unittestsuite = unittest.TestSuite()# 传入列表，这样就会按照元素顺序执行测试suite.addTests([TestMath('test_add'), TestMath('test_minus'), TestMath('test_string')])if __name__ == '__main__': unittest.main() 还可以通过unittest提供的TestLoader类来添加testcase，TestLoader会返回一个suite。不过TestLoader无法保证按照顺序执行测试。TestLoader类提供了一下常用方法：1234567891011from test_math import *# 三种方法都可以suite.addTests(unittest.TestLoader().loadTestsFromName('test_math.TestMath'))suite.addTests(unitest.TestLoader().loadTestsFromNanes(['test_math.TestMath'])suite.addTests(unitest.TestLoader().loadTestsFromTestCase(TestMath))# 如果test_math在/usr/test/目录下suite.addTests(unittest.TestLoader().discover(r'/usr/test/'))# 可用添加单个testcasesuite.addTest(TestMath('test_add')) loadTestsFromName(模块名.testcase名) loadTestsFromTestCase(testcase名) discover(start_dir, pattern=’test.py’, top_level_dir=None)。start_dir是目标文件夹路径，unittest会查找指定目录及子目录下的全部符合pattern的模块并执行里面的TestCase。电脑中不能有同名的目标文件夹，否则unittest可能无法找到正确的位置。patter默认是’test.py’。搭建测试环境TaseCase父类提供了setUp()，tearDown()，setUpClass()，tearDownClass()。我们在自己的测试用例中重写就可以了。 setUp()与tearDown()会在每个测试之前执行。setUp()负责搭建测试环境，tearDown()负责清理环境。如果setUp()执行失败那么这次测试不会进行，如果setUp()成功执行那么不管测试是否成功tearDown()都会执行。1234567891011121314151617import unittestfrom manage import create_app, dbclass TestBasic(unittest.TestCase): def setUp(self): self.app = create_app('TESTING') self.app_context = self.app.app_context() self.app_context.push() self.client = self.app.test_client(use_cookies=True) db.create_all() def tearDown(self): db.session.remove() db.drop_all() self.app_context.pop() ... 如果想要在所以case之前执行一次环境准备，所有case之后清理环境，可用setUpClass()和tearDownClass()。不过要带上@classmethod装饰器。12345678910111213141516171819import unittestfrom manage import create_app, dbclass TestBasic(unittest.TestCase): @classmethod def setUp(cls): cls.app = create_app('TESTING') cls.app_context = cls.app.app_context() cls.app_context.push() cls.client = cls.app.test_client(use_cookies=True) db.create_all() @classmethod def tearDown(cls): db.session.remove() db.drop_all() cls.app_context.pop() ... 执行测试及控制输出通常我们使用unittest.main()就会调用Test Runner开始测试。当然也可以手动执行Runner。123if __name__ == "__main__": runner = unittest.TextTest.Runner(verbosity=2) runner.run(suite) verbosity设定了测试报告的详细程度，有0，1，2三种。默认值是1，数字越大越详细。 也可以把输出写到文件里,将文件指针传给Runner()里的stream参数就可以了：123with open('/usr/test/report', 'w') as f: runner = unittest.TextTest.Runner(verbosity=2, stream=f) runner.run(suite) 跳过测试unittest提供3种跳过测试的装饰器：skip([reason])、skipIf(condtion[,reason])，skipUnless(conditon[,reason])。12345678910111213from mathfunc import *import unittestclass TestMath(unittest.TestCase): @unittest.skip('跳过add函数') def test_add(self): self.assertTrue(1+2, add(1, 2)) def test_minus(self): self.assertEqual(2-1, minus(2, 1)) def test_string(self): self.assertIn('h' in string('hello'))]]></content>
      <categories>
        <category>Web开发</category>
      </categories>
      <tags>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常见用法]]></title>
    <url>%2F2018%2F05%2F23%2Fgit%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[使用git也有一段时间了，一直没有做总结，在这里记录一下方便以后查看。 安装gitwindows下直接从官网下载就可以了，安装过程是傻瓜式的，一路点确定就OK。安装完成后发现多了个叫git bash的程序，打开程序会弹出一个命令行窗口就可以了。 linux下安装git很简单，直接在终端输入git，系统会告诉你是否已经安装。如果没有安装还会告诉你安装方法。Debian和Ubantu下通过sudo apt-get install git就可以进行安装。 配置git由于git是分布式版本控制系统，所以必须指出每台机器的身份。这就要配置git相关变量：12git config --global user.username &quot;name&quot;git config --global user.email &quot;email&quot; 有时候我们发现自己的账户和邮箱配置错了，重设我们的账户和邮箱：12git config --global --replace-all user.username &quot;new name&quot;git config --global --replace-all user.email &quot;new email&quot; 创建版本库cd到目标文件夹下，打开git bash或在终端输入：1git init 这就创建了一个版本库，有了版本库就可以开始使用git的各项功能了。 git分区git有分区的概念，平时我们新建、删除、修改文件都是在工作区，通过git add命令把工作区的变动提交到暂存区(stage)，再用git commit把stage的内容提交到分支。 查看git状态12git status #查看当前仓库的状态（是否有文件被修改，有文件没有commit等）git diff file #用于比较工作区版本与缓存区版本的不同 git指出有一个modified：learngit.txt,且not staged(没有提交至暂存区) 添加远程仓库想把github中的仓库和本地仓库关联起来，就要先在github中添加这台机器的ssh。可以通过1ssh-keygen -t rsa -C &quot;email&quot; 来获得本机的ssh密钥，这条命令会在当前文件夹下生成.ssh文件夹，里面有两个文件：id_rsa和id_rsa.pub。带pub的是公钥，把id_rsa.pub里的内容添加到github上。 远程仓库与本地仓库通过这条命令可以实现，”url”是远程仓库的网址：1git remote add origin &quot;url&quot; origin就是这个git本地仓库对远程仓库的称呼，也可以用别的名字，但是通常都用origin。 删除本地仓库与远程仓库的关联也很简单：1git remote remove origin 把本地库内容推送到远程1git push origin master 如果是第一次推送，可以为push加上-u参数，这样以后推送的时候就不用再输入github的账号和密码了。master代表远程仓库的主分支，如果要推送到其他分支就换成其他分支名。 抓取远程库内容抓取远程仓库内容并merge到本地1git pull origin 克隆一份仓库有时候我们在github上可能看到一些很有意思的库，可以用这个命令把它下载到本地，其中”url”是这个仓库的网址：1git clone &quot;url&quot; 显示过往提交记录12git log # 显示提交日志，每次提交会有一个专属的版本号，通过版本号可回溯至本次提交git log --pretty=oneline # 在log显示信息过乱时可以加 --pretty=online参数，只显示提交记录及其版本号 HEAD表示这是当前版本，可以用HEAD^表示上一版本，HEAD^表示上上版本…HEAD~100表示第前100个版本。 版本回退使用git的一个主要好用就是git提供方便的版本控制，可以在需要的时候回退到任意版本。 版本回退命令：1git reset --hard &apos;版本号&apos; 版本号可以用git log查询，结合这两个命令就可以实现版本回退啦~ 但是这里有个问题：当我们回到历史版本后，git log命令就无法显示最新版本的版本号。相当于我们穿越到过去，却没办法回来了。幸好git relog命令可以解决这个问题，git relog记录了每一次命令： 在这个例子中，可以通过git reset --hard 78ab7e9从be2a4ae回退到78ab7e9版本。 管理修改有时我们修改了工作区或暂存区的文件，过了一会儿又后悔了，可以用下面的命令撤销这些修改：1git checkout file 如果文件已经commit到了暂存区，想要把它从暂存区里撤下来也是可以的：1git reset HEAD file 处理冲突在合并分支时，可能会遇到两个分支的内容有冲突而导致合并失败的现象（这在执行pull操作时尤其常见，特别是当你在github上在线修改了一个文件，而本地没有修改时）。git会在冲突文件中用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同内容的分支。我们需要将文件进行修改后再执行git commit：12345678910111213# 可以看到，两个分支冲突了&lt;&lt;&lt;&lt;&lt;&lt;HEADgit is good=======git is very good&gt;&gt;&gt;&gt;&gt;&gt;branch# 将文件修改一下git is very good# 提交git add test.txtgit commit -m &quot;解决冲突&quot;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Rest API设计]]></title>
    <url>%2F2018%2F05%2F17%2FRest-Api%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[近几年Web程序有种趋势，就是业务逻辑越来越转移到了客户端一侧，开创出了一种称为富互联网应用（RIA） 的架构。在RIA中，服务器的主要功能就是为客户端提高数据存取服务。在这种模式中，服务器变成了Web服务或应用编程接口（API）。 RIA可采用多种协议与Web服务通信。其中最常用的就是REST架构了，因为这种架构建立在大家熟悉的HTTP协议之上。 REST简介REST符合以下6种特征： 客户端-服务器客户端与服务器之间必须有明确的界限。 无状态客户端发出的请求中必须包含所有必要的信息。服务器不能在两次请求之间 保存客户端的任何状态。 缓存服务器发出的响应可以标记为可缓存或不可缓存。这样出于优化目的，客户端或客户端与服务器之间的中间服务可以使用缓存。 接口统一客户端访问服务器资源时使用的协议必须一致，定义良好且已经标准化。REST Web服务最常使用的统一接口是HTTP协议。 系统分层在客户端与服务器之间可以按需插入代理服务器，缓存或网关义提高性能，稳定性和伸缩性。 按需代码客户端可以选择从服务器上下载代码，在客户端的环境中执行。 错误处理当客户端从Web服务获得404与500响应时会有点小麻烦，因为这两个错误是Flask自己生成的，而且一般会返回HTML响应，这可能会让API客户端感到困惑。 为所有客户端生产响应的一种方法是在错误处理程序中根据客户端请求的格式改写响应。这种技术被称为内容协商。12345678@main.app_errorhandler(404)def page_not_found(error): if request.accept_mimetypes.accept_json and \ not request.accept_mimetypes.accept_html: response = jsonify(&#123;'error': 'not found'&#125;) response.status_code = 404 return response return render_template('404.html'), 404 Werkzeug将Accept请求首部解码为request.accept_mimetypes,根据首部的值决定客户端期望接收的响应格式。 其他状态码都是由Web服务生成，因此可在蓝本的errors.py模块作为辅助函数实现。这样Web服务就可以在视图函数中使用这些辅助函数了。1234def forbidden(message): response = jonify(&#123;'error': 'forbidden', 'message': message&#125;) response.status_code = 403 return response 使用flask-httpauth认证用户和普通的Web程序一样，Web服务也需要保护信息，确保未授权用户无法访问。为此RIA必须询问用户的登录密令并将其传给服务器进行询问。 默认情况下，Flask把会话存在客户端的cookie，因此服务器没有保存任何用户相关的信息，都交给客户端去保存。而然在REST Web服务中使用cookie有点不现实，因为除了Web浏览器之外别的客户端都很难提供对cookie的支持。这样一来，验证信息的处理不得不移交到服务器一端，由于REST是无状态的，每次向服务器发起请求都不得不重新进行验证。 因为RESET架构基于HTTP协议，所以发送密令的最佳方式是使用HTTP认证，基本认证和摘要认证都可以。在HTTP认证中，用户密令包含在请求的Authorization首部中。 什么是HTTP认证？HT通过HTTP报文中首部字段（通常是Authorization）的特定值实现认证，不同于使用cookie，这种通过HTTP协议进行身份认证的过程称为HTTP认证。常见的HTTP认证方法有HTTP基本认证(Http Basic Authentication) 与HTTP摘要认证(Http Digest Authentication)。 Flask-httpauth通过pip进行安装：pip install flask-httpauth。和Flask-login扩展一样，Flask-httpauth不对验证用户密令所需要的步骤做必要的假设。因此所需的信息在回调函数中提供。12345678910111213141516from model import Userfrom flask import gfrom flask_httpauth import HTTPBasicAuth# 初始化一个HTTPBasicAuth类auth = HTTPBascicAuth()@auth.verify_passworddef verify_passwrod(email, passwd): if email == '': return False user = User.query.filter_by(email=email).first() if not user: return False g.current_user = user return user.verify_password(passwd) 如果账号和密码都正确，验证回调函数返回True,否则返回False。同时，验证回调函数把通过认证的用户保存在Flask的全局对象g中，如此一来视图函数便能进行访问。 如果认证密令不正确，服务器向客户端返回401错误信息。默认情况下Flask_httpauth会自动生成这个状态码，但为了和API返回的其他错误一致我们可以自定义这个错误响应：12345678from flask import jsonify# Flask_httpauth的错误处理程序@auth.errorhandlerdef auth_error(): response = jsonify(&#123;'error': 'Unauthorized', 'message': '密令错误！'&#125;) response.status_code = 401 return response 为了方便我们可以将401，500等错误状态的响应单独写成函数1234def unauthorized(message): response = jsonify(&#123;'error': 'Unauthorized', 'message': message&#125;) response.status_code = 401 return response 这样我们的错误处理程序就变得很简洁：123@auth.error_handlerdef auth_error(): return unauthorized('密令错误！') 为了保护路由，实现每次访问API时都需要通过认证，可以使用Flask的钩子函数before_request12345@api.before_request@auth.login_requireddef before_request(): if not g.current_user: return unauthorized('未认证！') 基于令牌的验证每次请求时，客户端都要发送信息，为了避免总是发送敏感信息，可以提供一种基于令牌的验证方案。 使用基于令牌的验证方案时，客户端要先把登录密令发送给一个特殊的URL，从而生成认证令牌，一旦客户端获得令牌就可用令牌代替密令完成认证。出于安全考虑令牌总是要设置一个有效期，令牌过期后就必须重新获取一个令牌。123456789101112131415161718from itsdangerous import TimedJSONWebSignatureSerializer as Serializerclass User(UserMixin, db.Model): # ... def generate_token(self,expiration): s = Serializer(secret_key=app.config['SECRET_KEY'], expires_in=3600) # 根据id字段生成令牌 return s.dumps(&#123;'id': self.id&#125;) @staticmethod def verify_token(token): s = Serializer(secret_key=app.config['SECRET_KEY']) try: id = s.loads(token)['id'] except: return None user = User.query.get_or_404(id) return user generate_token()方法使用编码后的用户id字段生成一个令牌，还指定了这个令牌的有效时间。verify_token()方法接受一个token，如果令牌可用就返回对应的用户。 这里扩展一下itsdangerous模块。这个模块可以用来生成各种密令。下面是常用的几个类 TimedJSONWebSignatureSerializer,根据当前Json签名草案来生成header TimestampSigner,如果你想要可以过期的签名，可以使用 TimestampSigner 类，它会加入时间戳信息并签名。在反签名时，你可以验证时间戳有没有过期 12345from itsdangerous import TimestampSigners = TimestampSigner('secret_key')data = s.loads('hello')# max_age表示当前时间与签名时间之差，以s为单位print(s.dumps(data, max_age=10)) URLSafeSerializer,如果能够向只有字符受限的环境中传递可信的字符串的话，将十分有用。因此，itsdangerous也提供了一个URL安全序列化工具 在python3中，loads()方法返回值往往是byte类型 为了使验证回调函数支持令牌验证，必须要改进它：12345678910111213141516@auth.verify_passworddef verify_password(email_or_token, passwd): if email_or_token: return False if passwd: user = User.varify_token(email_or_token) if user: g.currnet_user = user g.token_used = True return True user = User.query.filter_by(email=email_or_token).first() if user: g.current_user = user g.token_used = False return user.verify_password(passwd) return False 把认证令牌发送给客户端的路由发送到api蓝本中。为了避免客户端使用旧令牌申请新令牌，要在视图函数中验证g.token_used，如果使用了令牌就拒绝请求。123456@api.route('/token')def generate_token(): if g.token_used: return unauthorized('令牌已存在') token = g.current_user.generate_token(expiration=3600) return josnify(&#123;'token': token.decode('utf-8'), 'expiration': 3600&#125;) 资源和JSON序列化转换开发Web服务时，经常需要在资源和json之间进行转换。json是HTTP请求和响应使用的传输格式。123456789101112class Post(db.Model): # ... def to_json(self): json_post = &#123; 'uri': url_for('api.get_post', id=self.id, _external=True), 'body': self.body, 'timestamp': self.timestamp, 'author': url_for('api.get_user', id=self.author_id, _external=True), 'comments': url_for('api.get_post_comments', id=self.id, _external=True), 'comment_count': self.comments.count() &#125; return json_post uri,author,comments字段分别返回各自资源url，因此它们使用url_for()函数生成。所有url_for()方法都指定了_external参数，这样就会生成完整url而不是生成传统Web程序中常用的相对url。 同样的，可以构造一个方法把json转换成资源：12345678class Post(db.Model): # ... @staticmethod def from_json(json_post): body = json_post.get('body') if body is None or body == '': raise ValueError('body字段值错误！') return Post(body=body) 用get()方法从json获得body字段。永远不要相信客户端送来的值，所以对获得的值进行检查是必须的。当body值为空时抛出ValueError错误，因为此时服务器没有足够的信息来判断到底是哪里有问题，只能抛出错误让客户端来处理。 实现资源端点现在我们需要实现用于处理不同资源的路由。原则上我们需要为api使用@auth.login_requied来保护路由，但是由于前面实现了before_request()就不需要写那么多重复代码了。1234567891011121314151617@api.route('/posts')def get_posts(): posts = Post.query.all() return jsonify(&#123;'posts': [post.to_json() for post in posts]&#125;)@api.route('/user/&lt;int:id&gt;')def get_user(id): user = User.query.get_or_404(id) return jsonify(&#123;'user': user.to_json()&#125;)@api.route('/posts',methods=['POST'])def new_post(): post = Post.from_json(request.json) post.author_id = g.current_user.id db.session.add(post) db.session.commit() return jsonify(post.to_json()) 注意：为了便于客户端操作，响应的主体中包含了新建的资源，这样客户端就无需在创建资源后再发起一个GET请求来获取资源。 分页大型资源整合对大型资源来说，获取全部集合的get请求消耗很大，而且难以管理。和Web程序一样，Web服务也可以对集合进行分页。12345678910111213141516171819@api.route('/posts')def get_posts(): page = request.arg.get('page', 1, type=int) pagination = Post.query.paginate( page, per_page=10, error_out=False ) posts = pagination.items prev = None if pagination.has_prev: prev = url_for('api.get_posts', page=page-1, _external=True) next = None if pagination.has_next: next = url_for('api.get_posts', page=page+1, _external=True) return jsonify(&#123; 'posts': [post.to_json() for post in posts], 'next'： next, 'prev': prev, 'conut': pagination.total &#125;) json响应格式中的posts字段依旧包含各篇文章，但现在这只是完整集合的一部分。如果资源有上一页和下一页，prev和next字段分别表示上一页和下一页资源的url。count是集合中博客文章的总数。 这种技术可用于所有返回集合的路由。]]></content>
  </entry>
  <entry>
    <title><![CDATA[《Python cookbook》第一章]]></title>
    <url>%2F2018%2F05%2F13%2F%E3%80%8APython-cookbook%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[dict dict的key是唯一的，而values不保证唯一。 dict()函数语法：参数说明 **kwargs – 关键字 mapping – 元素的容器。 iterable – 可迭代对象123class dict(**kwarg)class dict(mapping, **kwarg)class dict(iterable, **kwarg) 下面这三种调用方式是可接受的123dict(a='hello',b='hi') # &#123;'a':'hello','b':'hi'&#125;dict(zip(['a','b'],['hello','hi'])) # 映射函数方式构造字典，zip()返回一个迭代器 &#123;'a':'hello','b':'hi'&#125;dict([('a','hello'),('b','hi')]) # &#123;'a':'hello','b':'hi'&#125; 让key映射到多个values上多数情况下，字典的key与values并不是1对1而是1对多。例如：123456789d = &#123; 'a':[2,2,3], 'b':[3,3,4]&#125;e = &#123; 'c':&#123;35,345&#125;, 'd': &#123;3222,89&#125;&#125; values是使用list还是set完全取决于需要，如果要保持顺序就用list，如果要保证唯一性而顺序不是那么重要就用set。如果手动创建一个list或者set来存放values，再将之与key对应起来会使代码很混乱。这时可以用collenctions模块的defaultdict()类。123456789from collections import defaultdictd = defaultdict(list)d['a'].append(2)d['a'].append(2)d['a'].append(3)e = defaultdict(set)e['c'].add(35)e['c'].add(345) 让dict保持有序通常情况下，当我们对字典做迭代时，并不能保证迭代是按排列顺序进行的。我们想创建一个字典，同时当对字典做迭代或序列化操作时，也能控制其中元素的顺序。可以使用collections模块中的OrderDict类。当对字典做迭代时，它会严格按照元素初始添加的顺序进行。值得一提的是，OrderDict()内部维护了一个双向列表用于记录dict本身与key添加顺序，所以它的大小也是一般dict的两倍多。123456789from collections import OrderDictd = OrderDict()d['foo'] = 1d['bar'] = 2d['spam'] = 3for key in d: print(d[key])# 输出1,2,3 这在我们要精确控制json的时候特别有用：12import jsonjson.dumps(d) # 将一个OrderedDict对象转化为json 与字典有关的计算问题我们想在字典上进行各式各样的计算，如求最小值、最大值，排序等。假设我们有这样一个字典：12345price = &#123; 'Apple': 10, 'Banana': 8, 'Pear': 12,&#125; 如果尝试在字典上执行常见的数据操作，将发现它们只会处理键，而不是值。例如：12max(price) # Pearmin(price) # Apple 通常这没有意义，因为我们更多时候是想要对values进行处理，当然可以将price.values()作为参数传给比较函数，即使这样也没有意义，因为我们想知道最值对应的key（如最贵的水果是什么）。利用zip(iterable，iterable)函数的解决方案是生成一个values-key生成器。zip有拉链的意思，这个函数就像拉链一样把两个迭代对象的值一一对应起来，每组对应起来的值放在一个二元tuple中。 在这样的元组中进行比较时，values会先进行比较，然后才是key。例如我们可以这样找出最贵与最便宜的水果：12max(zip(prices.values(), prices.keys())) # (12, 'Pear')min(zip(prices.values(), prices.keys())) # (8, 'Banana') 找出两个字典的相同点这很像数学上的交集。类似的操作还有求并集，差集。python中的set就是一个典型的集合对象，符合集合的一切特征：无序性，唯一性。（由于集合的无序性，set并不保证元素的顺序是固定的，所以不支持索引操作，类似的dict也是无序的，所以也不支持位置索引） 考虑下面两个dict12345678910a = &#123; 'x': 100, 'y': 80, 'z': 150,&#125;b = &#123; 'x': 100, 'y': 39,&#125; dict的keys()方法与items()方法返回的都是集合对象，所以可以直接对其应用常用的集合操作。12345678# 找出a与b的交集a.items() &amp; b.items() # &#123;('x', 100)&#125;# 找出a与b的key交集a.keys() &amp; b.keys() # &#123;'x', 'y'&#125;# 找出a与b的不同a.items() - b.items() # &#123;('z': 150), ('y', 80)&#125; dict的values()方法并不支持集合操作，这是由dict的values没有唯一性决定的。如果想对values进行集合操作就要先用set()方法将values转化为集合。 对切片命名随着代码越来越复杂，时间越隔越久，当初做切片时为什么要选那几个数字早就想不起来了。这时代码已经无法阅读，到处都是硬编码的切片索引。我们对切片命名，这样大大增加了代码的可阅读性。 内置的slice()函数会创建一个切片对象，可以用在任何允许进行切片操作的地方。与普通的切片操作一样，slice()的截取是前闭后开的12345a = slice(6,)b = slice(0,None,2)x = 'hello world'print(x[a]) # 'world'print(x[b]) # 'hlowrd' 筛选列表中的元素有时我们想要对一个列表中的元素进行筛选，常用的方法有以下几种： 列表推导式找出列表中比50000大的数并将其余的数视为1:12l = [12646, 34, 233426, 987346, 35436, 3867][i if i &gt; 50000 else 1 for i in l] # [1, 1, 233426, 987346, 1, 1] 如果元素比较多，为了避免占用过多内存，可以改用生成器表达式。生成器表达式与列表推导式相似，把方括号改成圆括号就可以了：1234567l = [12646, 34, 233426, 987346, 35436, 3867]k = (i if i &gt; 50000 else 1 for i in l)next(k) # 1next(k) # 1next(k) # 233426next(k) # 987346# ··· 匿名函数与java类似，python也有匿名函数lambda()。其语法如下： lambda [arg1[, arg2, … argN]]: expression 匿名函数顾名思义就是没有名字的函数。有时一些函数只在某个特定的地方用1次，如果对这种函数命名很容易污染命名空间。通过lambda()可以快速定义一个简单的函数，注意：lambda()会将expression作为返回值：1(lambda x, y: x + y)(1, 2) # 3 map()map(function, sequence)提供一种映射，对sequence的每个元素都调用一次function。如果对元素的处理比较复杂，不适合写在列表推导式里，可以用map()，map()创建了一个迭代器：12345678910111213def hello(name): if name != 'Lucy': return 'hello ' + name return 'Woops'g = map(hello, ['Mike', 'David', 'Luck','Susan'])next(g) # 'hello Mike'next(g) # 'hello Davidn'next(g) # 'Woops'next(g) # 'hello Susan'g = map(lambda x, y: x + y, range(1,10), range(1, 10))list(g) # [2, 4, 6, 8, 10, 12, 14, 16, 18] filter()与map(function, sequence)类似，filter(function, sequence)也提供了一种映射，对sequence的每个元素都调用一次function。不同之处在于map()将function的返回值放入迭代器中，而filter()将使function为True的元素放入迭代器。12345678910def is_num(n): try: int(n) return True except: return Falsel = ['a', 'b', 354, 87, 'g']g = filter(is_num, l)list(g) # [354, 87]]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python常用库]]></title>
    <url>%2F2018%2F05%2F06%2FPython%E5%B8%B8%E7%94%A8%E5%BA%93%2F</url>
    <content type="text"><![CDATA[时间与日期python提供了time库和基于time的datetime库来处理时间。除此之外还有个很好用的第三方库Arrow。现在暂时先介绍time和datetime。 time程序休眠sleep(secs)让程序休眠指定的时间。12import timetime.sleep(10) 获取时间戳time包基于C语言的库函数(library functions)。Python的解释器通常是用C编写的，Python的一些函数也会直接调用C语言的库函数。time提供一个重要的函数time()，这个函数以浮点数的形式返回时间戳（timestamp）。每个时间戳都以自从1970年1月1日午夜（历元）经过了多长时间来表示。在python中，时间戳是一个6位浮点数12import timeprint(time.time()) # 输出1525572057.556286 格式化时间获取当地时间在做日期运算或者爬虫时，timestamp非常有用，但是对于人来讲就不是那么好阅读了。为了获取易于阅读的时间格式，我们常用localtime([secs])函数。localtime()会返回一个由当地系统时区决定的tupletime。tupletime存放了年，月，日，时，分，秒等一系列的时间信息。可以给localtime()传递一个时间戳，返回这个时间戳的tupletime,如果没有给localtime()传参，根据当前时区返回tupletime。12import timeprint(time.localtime()) # 输出 time.struct_time(tm_year=2018, tm_mon=5, tm_mday=6, tm_hour=10, tm_min=9, tm_sec=3, tm_wday=6, tm_yday=126, tm_isdst=0) 获取UTC时间gmtime()与localtime()类似，但是它是返回由UTC时间决定的tupletime。gm是Greenwich Mean Time(格林尼治平均时)的简写 格式化tupletime有了time结构体，我们就可以把它格式化，常用strftime(fmt[,tupletime])函数。接收时间元组，并返回以可读字符串表示的当地时间，格式由fmt决定。123import timeprint(time.strftime('%Y-%m-%d-%H-%M-%S',time.localtime())) # 输出 '2018-05-06-10-07-03'print(time.strftime('%w',time.localtime())) # 输出 '0' python中时间日期格式化符号： %y 两位数的年份表示（00-99） %Y 四位数的年份表示（000-9999） %m 月份（01-12） %d 月内中的一天（0-31） %H 24小时制小时数（0-23） %M 分钟数（00=59） %S 秒（00-59） %a 本地简化星期名称 %A 本地完整星期名称 %b 本地简化的月份名称 %B 本地完整的月份名称 %c 本地相应的日期表示和时间表示 %j 年内的一天（001-366） %w 星期（0-6），星期天为星期的开始 %x 本地相应的日期表示 %X 本地相应的时间表示 格式化tupletime为可读时间用asctime([tupletime])获取一个可读的时间。如果没有tupletime参数，默认返回当前时间123import timet = time.localtime()print(time.asctime(t)) # 输出 'Sun May 6 10:41:52 2018' datetime通常我们是对datetime包里的datetime类进行操作。所以下面的代码开头都要加上一句：1from datetime import datetime 获得指定日期和时间通过给datetime类传参可以直接构造一个datetime对象，之中year，month，day这三参数是必要的。1234dy1 = datetime(2018, 5, 22)print(dy1) # 2018-05-22 00:00:00dy2 = datetime(2018, 5, 22, 21, 31)print(dy2) # 2018-05-22 21:31:00 获取当前时间now()根据当前时区返回datetime对象。12&gt;&gt;&gt; datetime.now() # datetime.datetime(2018, 5, 22, 21, 23, 36, 479464)&gt;&gt;&gt; print(datetime.now()) # 2018-05-22 21:28:17.010318 datetime转为timestamp把一个datetime对象转为timestamp只需要调用timestam()方法，在python中，时间戳是一个6位浮点数:12now = datetime.now()print(now.timestamp()) # 1526996172.579076 timestamp转为datetime要把timestamp转为datetime对象，使用datetime提供的fromtimestamp()方法，可以直接获得当前时区的datetime对象：12timestamp = 1526996172.579076print(datetime.fromtimestamp(timestamp)) # 2018-05-22 21:36:12.579076 要获得UTC时间也可以，用utcfromtimestamp()方法:12timestamp = 1526996172.579076print(datetime.utcfromtimestamp(timestamp)) # 2018-05-22 13:36:12.579076 datetime格式化成字符串对用户来说，datetime对象太难阅读了。可以用strftime(fmt)实现，fmt是一个格式化字符串，其格式与上文中time.strftime(fmt[,tupletime])的相同12&gt;&gt;&gt; dt = datetime.now()&gt;&gt;&gt; dt.strftime('%Y-%b-%d %H:%M:%S') # '2018-May-22 21:49:50' 字符串转化成datetime从用户那儿获得的输入往往不能直接用，必须要经过处理成datetime对象，这时可用datetime.strptime(time,fmt)，需要一个日期和格式化字符串。fmt的连接符必须与time相同，有点类似于正则表达式12cday = datetime.strptime('2018-5-22 21:56:23', '%Y-%m-%d %H:%M:%S')print(cday) # 2018-05-22 21:56:23 拿到当前UTC时间用datetime.utcnow()即可实现：12&gt;&gt;&gt; datetime.utcnow() # datetime.datetime(2018, 5, 22, 14, 4, 3, 725937)&gt;&gt;&gt; print(datetiem.utcnow()) # 2018-05-22 14:04:50.759558 操作文件和目录Python内置的os模块可以调用操作系统提供的接口函数，对文件或目录进行操作(实际上操作系统是不允许应用程序直接访问和操作文件和目录的，读写文件就是请求操作系统打开一个文件对象，通常称为文件描述符。然后，通过操作系统提供的接口从这个文件对象中读取数据，或者把数据写入这个文件对象。) os包)查看目录或文件的的绝对路径用os.path.abspath(&#39;pos&#39;)12import osprint(os.path.abspath('.')) # 输出 'C:\\Users\\86728' 对路径进行连接组合os.path.join(pos1, pos2),可以直接处理不同系统的路径分隔符。12import osprint(os.path.join(os.path.abspath('.'),'qiuyue')) # 输出 'C:\\Users\\86728\\qiuyue' 对路径进行拆分os.path.split(pos)，最后一部分总是最后级别的目录或文件。返回一个2元tuple。12import osos.path.split('C:\\Users\\86728\\qiuyue\\test.txt') # 返回('C:\\Users\\86728\\qiuyue','test.txt') 得到文件后缀名os.path.splitext(pos)。返回一个2元tuple。12import osos.path.splitext('C:\\Users\\86728\\qiuyue\\test.txt') # 返回('C:\\Users\\86728\\qiuyue\\test','.txt') 创建单个目录os.mkdir()会在目录下面创建一个空目录12import osos.mkdir('qiuyue') 创建多级目录os.makedirs(pos)，可以理解为一种递归创建。12import osos.makedirs('C:\\Users\\86728\\qiuyue\\test\\hello\\world') 重命名一个文件os.rename()。12import osos.rename(test.txt, test.py) # 将test.txt重命名为test.py 删除一个文件os.remove(pos)12import osos.remove('test.txt') shutil包复制文件的函数居然在os模块中不存在！原因是复制文件并非由操作系统提供的系统调用。为了解决这个问题，需要用到shutil包。 复制文件夹shutil.copytree(olddir, newdir)。olddir和newdir都只能是目录，且newdir必须不存在。 复制文件shutil.copy(oldfile, newfile),oldfile只能是文件。而newfile可以是文件，也可以是目录。123import shutilshutil.copy('test1.txt','test2.txt') # 在当前目录下创建一份名为test2.txt的test1.txt的拷贝shutil.copy('test1.txt','C:\\Users\\86728') # 在C:\Users\86728目录下创建一份与test1.txt同名的拷贝 移动文件（目录)shutil.move(&#39;oldpos&#39;,&#39;newpos&#39;)123import shutilshutil.move("myfile1.txt", "../") # 把myfile1.txt移动到当前目录的父目录，然后删除myfile1.txtshutil.move("myfile2.txt", "myfile3.txt") # 重命名myfile2.txt 删除目录用shutil.rmtree(pos)删除一个目录，无论它是否为空。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Nginx与gunicorn]]></title>
    <url>%2F2018%2F04%2F29%2FNginx%E4%B8%8Egunicorn%2F</url>
    <content type="text"><![CDATA[gunicorn众所周知，Web应用最后是要放到网络上的。而我们平时写的Web应用只是一个应用而已，想要把应用放到网络上，成为server，我们就需要有服务器来对http请求进行解析，这样才能让别人访问我们的Web应用。对于Python应用来说gunicorn就是这样一个网关服务器，运行在linux平台，遵循WGSI协议。其性质类似于java里的Tomcat。通常，我们把写好的Web应用放在gunicorn里，这样别人向gunicorn发出请求，再由gunicorn根据Web应用对请求做出响应并返回，就完成了一次访问-响应过程。安装gunicorn的方式很简单：1pip install gunicorn 要使用gunicorn，常用的命令是：1gunicorn [-option] module:application 常用的option有： -w w是worker的简写。在多核服务器上，为了支持更多的并发访问并充分利用资源，使用更多的进程，我们就可以指定worker数量，比如指定 -w 4就可以启动4个进程同时处理http请求,提高系统的效率及性能。 -b b是bind的简写。绑定gunicorn监听端口。如-b 0.0.0.0:5000会在公网上运行你的Web应用，通过访问公网ip:5000就可以访问你的Web应用。 -k gunicorn默认使用同步阻塞的网络模型(-k sync)，对于大并发的访问可能表现不够好，它还支持其它更好的模式，比如：gevent，gevent是一个基于libev的并发库，它为各种并发和网络相关的任务提供了整洁的API。gunicorn对于“协程”也就是Gevent的支持非常好。通过-k gevent的方式就可以指定使用gevent。gevent需要另外安装 module是应用所在的模块名，application当然就是你的Web应用名。 NginxNginx是高性能的Web服务器，性能好，高并发，可以做负载均衡，也是常用的反向代理服务器。那个首先要弄清楚两个问题：什么是反向代理，什么是负载均衡呢？ 反向代理反向代理的代理对象是服务器。也意味着用户做服务器域名解析时，解析得到的IP其实是负载均衡的IP，而不是服务器的IP，这样有一个好处是，当新加入/移走服务器时，仅仅需要修改负载均衡的服务器列表，而不会影响现有的服务。比如当我们访问百度时，我们会获得百度返回的html，css，js，img等资源，而这些资源很可能不是放在同一个服务器上的，换言之，你以为你是访问www.baidu.com后，从这个域名绑定的服务器上获得这些资源，就像这样：但其实这个服务器只是一个中介，它连接了很多很多的服务器，当它收到请求后，从各个服务器上获取相应的资源，再把这些资源返回给你。这样就能大大减轻每一个服务器的压力，就像这样： 正向代理有反向代理，自然就有正向代理。所谓正向代理，代理对象是客户端。比如你在科学上网的时候，想要访问谷歌，你的访问请求会被发到海外的代理服务器上，由这个代理服务器向谷歌发出请求，再把谷歌的响应返回到你的客户端上。这个过程就是正向代理，而你的客户端就是代理对象。总而言之，反向代理与正向代理关系就像这样： 负载均衡关于负载均衡，知乎上有一篇很不错的介绍文章:什么是负载均衡。 了解了一些基本知识后，让我们回到Nginx。通常，我们不会让用户直接访问gunicorn，而是在gunicorn上套一层Nginx。这首先是因为gunicorn对静态资源的加载不好，这时使用Nginx缓存静态资源可以明显提高用户体验。其次，有了这样一层服务器做缓冲，我们可以保留80端口，可以在后端部署一大堆服务器，万一有一台服务器宕机了，只要在负载列表中把这台机子down掉，再加一台新的就可以了。]]></content>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《MySQL从入门到精通》读书笔记]]></title>
    <url>%2F2018%2F03%2F31%2F%E3%80%8AMySQL%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[范式(Normal Form)关系型数据库的规范化理论为：关系数据库中的每一个关系都要满足一定的规范。根据满足规范的条件不同，可以分为5个等级，一般只要把数据库规范到第三等级就足够了。 第一范式(1NF)第一范式包括下列指导原则： 数据组中的每个属性只可以包含一个值 关系中的每个数组必须包含相同数量的值 关系中的每个数组一定不能相同在任何一个关系型数据库中，第一范式是对关系模式的基本要求，不满足第一范式的数据库就不是关系型数据库。 如果数据表中的每一个列都是不可再分割的基本数据项，即同一列中不能有多个值，那么就称此数据表符合第一范式，由此可见第一范式具有不可再分割的原子特性。 第二范式(2NF)第二范式是在第一范式的基础上建立起来的，即满足第二范式必须先满足第一范式。第二范式要求数据库表中的每个实体（即各个记录行）必须可以被唯一地区分。 为了实现区分各记录行通常需要为表设置一个“区分列”，用以存储各个实体的唯一标识。这个唯一属性列被称为主关键字或主键。 第三范式(3NF)第三范式是在第二范式的基础上建立起来的。第三范式要求关系表不存在非关键字列对任意候选关键字列的传递函数依赖，也就是说，第三范式要求一个关系表中不包含已在其他表中包含的非主关键字信息。所谓传递函数依赖，就是指如果存在关键字段A决定非关键字段B，而非关键字段B决定非关键字段C，则称非关键字段C传递函数依赖与关键字段A。参考下面的例子： (员工编码) ——&gt; (决定) (员工姓名、年龄、部门编码、部门经理) 上面这个关系表是符合第二范式的，但是不符合第三范式，因为该关系表内部隐含着如下关系： (员工编码) ——&gt; (决定) (部门编码) ——&gt; (决定) (部门经理) 上面的关系表纯真非关键字段“部门经理”对关键字段“员工编码”的函数传递依赖，对于上面这种关系，可以把这个关系表改为如下两个关系表： 员工信息表：(员工编码，员工姓名，年龄好部门编码)部门信息表：(部门编码和部门经理) 语句执行顺序MySQL的语句一共分为11步，如下图所标注的那样，最先执行的总是FROM操作，最后执行的是LIMIT操作。其中每一个操作都会产生一张虚拟的表，这个虚拟的表作为一个处理的输入，只是这些虚拟的表对用户来说是透明的，但是只有最后一个虚拟的表才会被作为结果返回。如果没有在语句中指定某一个子句，那么将会跳过相应的步骤。下面来分析一下这些语句： FORM: 对FROM的左边的表和右边的表计算笛卡尔积。产生虚表VT1 ON: 对虚表VT1进行ON筛选，只有那些符合的行才会被记录在虚表VT2中。 JOIN： 如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3,如果from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。 WHERE： 对虚拟表VT3进行WHERE条件过滤。只有符合的记录才会被插入到虚拟表VT4中。 GROUP BY: 根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5. CUBE | ROLLUP: 对表VT5进行cube或者rollup操作，产生表VT6. HAVING： 对虚拟表VT6应用having过滤，只有符合的记录才会被 插入到虚拟表VT7中。 SELECT： 执行select操作，选择指定的列，插入到虚拟表VT8中。 DISTINCT： 对VT8中的记录进行去重。产生虚拟表VT9. ORDER BY: 将虚拟表VT9中的记录按照进行排序操作，产生虚拟表VT10. LIMIT：取出指定行的记录，产生虚拟表VT11, 并将结果返回。 where和having的区别：where是在分组之前进行过滤，而having是在分组之后对条件进行判断。这里要提醒一下:select中的选择字段除非使用了聚合函数如SUM(),AVG()等，必须是group_by中的分组字段，否则会报错。这是因为在MYSQL5.7版本中，默认设置了sql_mode=only_full_group_by，这会导致select选择字段必须是group_by分组字段。要解决这个问题也很简单，只要使用命令SET sql_mode=(SELECT REPLACE(@@sql_mode,&#39;ONLY_FULL_GROUP_BY&#39;,&#39;&#39;));，或者在配置文件my.ini中将sql_mode修改为：’STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION’]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask学习]]></title>
    <url>%2F2018%2F03%2F22%2FFlask%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[flask的4种请求钩子有时在处理请求之前或者之后执行代码会很有用。例如：在请求开始时，我们可能需要创建数据库连接或者认证发起请求的用户，为了避免在每个视图函数中都有重复的代码，Flask提供了注册通用函数的功能，注册的函数可以在请求被分别发布到视图函数之前或之后自动调用。这种注册函数的功能就称之为“请求钩子”。 @before_first_request注册一个函数，在处理第一个请求之前执行。 @before_request注册一个函数，在每次请求之前执行。1234567891011from flask import Flaskapp = Flask(__name__)@app.route('/')def index(): return 'hi'@app.before_requestdef hello(): print('hello') @after_request注册一个函数，如果没有未处理的异常抛出，在每次请求之后执行。 @teardown_request注册一个函数，即使有未处理的异常抛出，也在每次请求之后运行。 flask的4种上下文全局变量Flask从客户端收到请求时，要让视图函数能访问一些对象，这样才能处理请求。要想让视图函数能够访问这些对象，一个显然的方法是把它们作为参数传入函数中，但这样一来每个视图函数都要加上这样的参数。为了避免大量的可有可无的参数把视图函数变得一团糟，Flask使用上下文把某些对象变得全局可访问。事实上这些对象不可能是全局变量。在多线程服务器中，多个线程同时处理来自客户端的不同请求时，每个线程看到的请求必然不同。Flask使用上下文让特定的变量在一个线程中全局可访问而不会干扰到其他线程。 请求上下文(request context)request请求对象，封装了客户端发出的HTTP请求中的内容。12345678910from flask import request,Flask,abortapp = Flask(__name__)@app.route('/',methods=['GET','POST'])def index(): if request.method == 'GET': return 'hello' else: abort(404) 这段代码表示当客户端以GET的方式发送HTTP请求时，会返回hello，否则abort()会抛出一个404错误。 request获取HTTP请求内容的几种方式 request.method获取HTTP请求方式 request.form.get(‘name’)获取form中的内容，当name不存在时返回None。(注意：用request.form[‘name’]也可以把内容取出来，但是任何时候都不应该用这种危险的方式，因为当name不存在时会直接抛出错误，下文同理) request.args.get(‘name’)获取以查询字符串中的内容，当name不存在时返回None。 request.cookies.get(‘name’)获取cookies中的内容，当name不存在时返回None。 request.headers.get(‘name’)获取HTTP请求的header中的内容，当name不存在时返回None。 request.url/base_url/path/url_root获取请求url相关内容，直接上结果方便理解：123return &apos;url: %s , path: %s , base_url: %s , url_root : %s&apos; % (request.url,request.script_root, request.path,request.base_url,request.url_root)#url: http://192.168.1.183:5000/testrequest?a&amp;b ,path: /testrequest , base_url: http://192.168.1.183:5000/testrequest , url_root : http://192.168.1.183:5000/ gg：global。处理请求时用作临时存储的对象，每次请求都会重设这个变量。g还常用于在请求钩子和视图函数之间共享数据。例如：before_request处理程序可以从数据库中加载已登录用户并将其保存到g.user中，随后调用视图函数时，视图函数就可以直接使用g.user获取用户。1234567891011121314151617181920212223242526272829from flask import Flask,g,request,render_templat,gdef login_log(): print ('当前登录用户是：%s' % g.username)def login_ip(): print ('当前登录用户的IP是：%s' % g.ip)app = Flask(__name__)@app.route('/')def hello_world(): return 'Hello World!'@app.route('/login/',methods=['GET', 'POST'])def login(): if request.method == 'GET': return render_template('login.html') else: username = request.form.get('username') password = request.form.get('password') g.username = username g.ip = password login_log() login_ip() return '恭喜登录成功！'if __name__ == '__main__': app.run() 程序上下文(app context)current_appcurrent_app，顾名思义这个变量表示当前激活的程序实例1234567from flask import current_app,Flaskapp = Flask(__name__)@app.route('/test')def index(): return current_app.name session用户回话，用于存储请求直接需要“记住”的值的字典，其操作方式也与字典相似。当客户端关闭则session失效。123456789101112131415161718192021from flask import Flask,session,url_forapp = Flask(__name__)@app.route('/login',methods=['GET','POST'])def login(): if request.method == 'POST': session['username'] = request.form.get('username') return url_for('index') return """ &lt;form action="" method="post"&gt; &lt;p&gt;&lt;input type=text name=username&gt; &lt;p&gt;&lt;input type=submit value=Login&gt; &lt;/form&gt;"""@app.route('/')def index(): if 'username' in session: return '%s 已经登录' % session['username'] return '请登录' Flask在分发请求之前激活程序和请求上下文，请求处理完成后再将其删除。程序上下文被推送后，就可以在线程中使用current_app和g变量。类似的，请求上下文被推送后，就可以使用request和session对象。如果使用这些变量时我们没有激活程序上下文和请求上下文，就会导致错误。通常程序上下文有Flask自动管理，但是也可以通过app.app_context()手动获得一个程序上下文：123app_context = app.app_context()app_context.push() # 激活app_context.pop() # 删除 蓝图为了方便开发和调试，我们用蓝图将程序分成一些不同的部分。每一部分相互独立。通常同一部分的程序url都带有相同的前缀，如:1http://127.0.0.1/user/1和http://127.0.0.1/user/2 创建蓝图通过flask自带的blueprint()就能创建一个蓝图：123456# !E:/web_develop/bp/__init__.pyfrom flask import blueprintbp = blueprint('bp',__name__)from . import views,errors blueprint接受两个参数：第一个参数是这个蓝图的名字，第二个参数是蓝图所在文件或模块的名字，通常是name注意：我们在创建蓝图后导入bp的视图函数模块views和错误处理模块errors，这是因为这两个模块中都有这一句：1from . import bp 这句话会从init.py中尝试导入bp，如果在创建bp前导入这两个模块，会出现循环调用的问题。 注册蓝图蓝图创建好了之后，还要在分发函数中注册它：123456789# !E:/web_develop/__init__.pyfrom flask import Flaskfrom .bp import bpdef create_app(): app = Flask(__name__) app.config.from_object('config') app.register_blueprint(bp,url_prefix='/bp') ... 通过register_blueprint()函数就可以注册这个蓝图，url_prefix属性指定url前缀。 在蓝图中创建视图函数在蓝图外，我们通常用@app.route()注册视图函数，在蓝图内，我们用@蓝图名.route()注册视图函数。如：1234567891011@bp.before_app_requestdef hello(): print ('hello')@bp.errorhandler(404)def error(e): return 'Not Found',404@bp.route('/hi')def hi(): return 'hi' 这样注册的函数的作用范围仅限于蓝图内。要让函数变得全局可用，我们要这样写：1234567@bp.app_errorhandler(404)def error(e): return 'Not Found',400@bp.before_app_requestdef hello(): print('hello')]]></content>
      <categories>
        <category>Web开发</category>
      </categories>
      <tags>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[书单整理]]></title>
    <url>%2F2018%2F03%2F20%2F%E4%B9%A6%E5%8D%95%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[这几天突发奇想，打算把高中毕业以来读过的书整理一遍，做个书单，方便日后查看，也可以给后来者一些参考。因为平时读的书比较杂，所以这份书单里的书也不仅限于一个方向，都是我读过以后觉得还不错的，推荐给大家。 悬疑推理老实说这方面的书我看的不多，印象比较深的就只有东野圭吾写的几本了(～￣▽￣)～ (～￣▽￣)～ 白夜行这个不多说，东野的代表作，基本上东野迷人手一本吧。如果你没看过推理小说，或者以前没有接触过东野圭吾，那么从入手这本书不会有错的~ 解忧杂货店东野另一代表作，在日本和国内分别都有翻拍的电影。建议看完书以后有兴趣的话可以看一下日本翻拍的那部电影，至于国产的嘛….如果你是王俊凯的粉丝可以看看￣ω￣=说回这本书，书里人物的命运相互交织，冥冥中似乎有一张巨大的网把他们联系在一起：为了躲避抓捕慌乱中躲进杂货店的小贼，被情所困的运动员，为未来彷徨的歌手…我常常会想，自己是否也会像书里说的那样，无意之间改变了他人的命运的走向。毕竟人生在世，没有谁是一座孤岛，再特立独行的人也必定会受到别人的影响。 嫌疑人X的献身如果说刚才两本书着力点在人心，这本书则更注重推理。数学天才为了包庇自己爱的人与警方斗智斗勇的故事。滴水不漏的思维，细致入微的推理，整个故事看下来还是很爽的。毕竟推理小说有点类似于复联这种爽片，能做到人文剧情两不误当然最好，如果不能，单是剧情精彩也就足够了。 编程嘿嘿，毕竟这小一年都在学习这方面的知识，所以这方面的书看得会多些￣ω￣=学习过程中踩过不少坑，有些书写的水平实在一般，有时自己又太着急了买了些自己还没办法理解的书，有时看完一本书后不知道下一步该怎么办…所以我会按自己的学习路线来给下面的书排版。不过要说明的是，我目前的学习方向是爬虫+后端开发，推荐的书也是以这两方面的居多。当然，现在网上有很多的教学视频，但是视频内容大多不全面，且对我来说视频学习效率不如看书，如果书上有内容看不懂，可以找些相关的视频来看看，有时候会有奇效。 C primer plusC入门的经典书籍，C是大部分现代编程语言之母，而且学习C的过程中你还会了解到很多关于计算机底层的知识，所以就算你不准备把C作为主力编程语言，起码也要了解C。这本书说实话挺厚的，不过千万不要被它的厚度吓到了，作为入门我们只需要学习它前半部分的内容，后面的算法知识可以等到以后再补。 Python编程-从入门到实战很不错的一本Python入门书，基于Python3（要知道python2在2020年就要停止维护了，所以现在入门的话python3是最佳选择）。基本把python基础语法都讲到了，每一个知识点都附有代码实例，章节末尾还有对应的练习。最可贵的是教学节奏把握的不错，学习的时候不会有很无聊的感觉。书末还有3个不错的实战项目，跟着这本书学下来python也就入门了。读完这本书之后如果想进一步加深对python的了解可以看一下廖雪峰老师的Python教程廖雪峰的python教程。这个教程也是python入门的好资料，不过难度跨越有点大，等有一点python基础之后看效果更好些。 图解HTTP初学HTTP的好书。学习http主要是因为后面的爬虫和web开发都要用到很多http方面的知识。这是一本日本人写的书，风格幽默风趣，最最棒的是书中有大量的插画帮助理解。类似的还有一本书叫《图解TCP/IP》,这里就不单独介绍了。 Python爬虫开发与项目实战既然已经入门了，当然要称热打铁，找些实际项目来练练手啦，爬虫就是一个很好的练手方向，看着数据一条条地被你从网上抓取下来，会很有成就感的~作为爬虫教程这本书写的很不错，从最基础的爬取静态网页开始，到爬取js渲染的动态网站，再到模拟登陆，处理验证码，反爬…还涉及分布式爬虫的内容。后半部分还对目前最火的python爬虫框架——Scrapy进行了讲解。读完这本书一般的网站都难不住你了。 Python核心编程(第三版)Python进阶书籍。有了一定的python开发基础后就可以看这本书了。主要学习其中的正则表达式，线程和进程，数据库编程，为接下来的Web开发做知识储备。 Flask Web开发备受好评的Flask学习书籍。每一章都有git tag，跟着作者一步步地完成一个web网站的开发。注意：学这本书一定要配合git使用，一步一步的跟着作者敲代码。如果不知道什么是git的可以先去看下廖雪峰的git教程廖雪峰的git教程。这本书写的很详细，学完基本就对flask比较熟悉了。想要了解更多可以看一下flask的文档，推荐看英文的Flask英文文档,如果英语比较差可以看下中文的Flask中文文档，不过最好还是看原文，毕竟翻译作品有时候难以表达作者原意。 数据结构与算法-python语言表述这是我最近在看的一本书，本来没看完的书不该推的，但是目前为止感觉很不错，所以也放上来了。。。本书由北大一名老教师编写，所以有一股很浓厚的国内教科书的气息(￣ー￣)不过讲的很详细，也比较好理解，关键是没有《算法导论》那么厚，比较容易让人接受。另一个原因是它是用python作为范例语言讲的，比较方便学习，哈哈未完待续。。。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>读书体会</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一点感想]]></title>
    <url>%2F2018%2F03%2F08%2F%E4%B8%80%E7%82%B9%E6%84%9F%E6%83%B3%2F</url>
    <content type="text"><![CDATA[今天开了个学情分析会，说实话我觉得很无聊。本来大学里的学习就不应该再像中学似的一切绕着成绩转，当然不是说成绩就不重要了，只是我想到了现在更重要的是磨炼自己的技能，增长见识。其实以前也好，现在也好，成绩讲究的是一个够用，这个标准自然因人而异：考二本的400+够用，要考清北的670+够用，想要混过4年的不挂科就够用，想要保研的3.5+才够用……对我而言，上学期的成绩是否够用还是个未知数，一切还要再等3个月才能知晓。不过不管是不是够用，大概都是有一个遗憾的：最重视的数学和英语学的并不好，这点倒是令我挺难受。其他的课程学的好也罢，差也罢，我并不是很在乎，唯独这两门我是没办法做到不在意的。还有就是写代码这件事了。接触这行也是机缘巧合。后来学得多了些，慢慢地也开始体会到乐趣所在，现在是CS的黄金年代，大量的人一拥而入，这是很正常的。但是不得不说如今的CS已经积累到了量变的程度，人工智能,区块链，云计算……这些方向都是多学科交叉的，统计学，数学，计算机科学，甚至物理学…以前那种能写些网站和app，会调个库，但是对底层一无所知还能被称为程序员的的时代已经快要过去了，未来必定会要求程序员对数据结构，算法，各种协议甚至硬件有更深的理解。路还很长，要努力啊]]></content>
      <categories>
        <category>心得</category>
      </categories>
      <tags>
        <tag>闲聊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《python核心编程》知识整理之正则表达式]]></title>
    <url>%2F2018%2F03%2F08%2F%E3%80%8Apython%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B%E3%80%8B%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%E4%B9%8B%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[特殊符号和字符正则表达式由多个字符组成，而有些字符在正则表达式中有特殊的含义，这部分字符被称为元字符。正是有了它们正则表达式才会如此强大。下面对一些常用字符做介绍。 择一匹配符：||&nbsp;起一个或的作用。如：12re.search(r'hello|hi','hello,jack.').group() # 匹配到hellore.search(r'hello|hi','hi,jack').group() # 匹配到hi 匹配任意单个字符：.. &nbsp;会匹配除了换行符\n和空字符以外的任意字符。1re.search(r'.end','end').group() # 匹配失败，因为匹配目标end的开头是一个空字符 从字符串的起始/结尾或者单词边界开始匹配：^,$,\b,\B^ &nbsp;会匹配字符串的起始部分1re.search(r'^From','From China') # 这样会匹配所有以From开始的字符串 $ &nbsp;会匹配字符串的末尾部分1re.search(r'jack$','hello,jack') # 这样会匹配所以以jack结尾的字符串 \b,\B 创建字符集：[ ]在[&nbsp; ]里面的字符相当于被多个或运算符相连。[0-9]会匹配0到9的任意一个数字，[a-z]会匹配a到z的任意一个字母。[^…]表示不匹配该字符集内的任意一个字符。如[^A-Z]表示不匹配所有的大写字母。 闭包操作符和频数匹配：*，+，？，{}闭包操作符都是对其左边的字符进行操作。* &nbsp;代表对其左边的正则表达式进行0次或者多次匹配。+ &nbsp;代表对其左边的正则表达式进行1次或多次匹配。? &nbsp;代表对其左边的正则表达式进行0次或者1次匹配。{M,N} {M}代表对其左边的正则表达式进行M到N次/M次匹配.以上都称作闭包操作符。 贪心模式和非贪心模式正则表达式在匹配时，尽可能多的进行匹配。比如说对于一个匹配目标，如果+既可以匹配1次，也可以匹配多次，正则表达式会优先匹配多次。这就是贪心模式。而在闭包操作符后面加上?就可以进入非贪心模式，按尽可能少的次数进行匹配。12345data = 1111aa1re.search(r&apos;\w+(\d)&apos;).group(1) # 这样是无法取到分组1中的匹配对象的，因为\w+就已经把全部字符串匹配完毕。re.search(r&apos;\w+?(\d)&apos;).group(1)# 这样分组1中的匹配对象就是1，对应data中的第二个1。 使用圆括号进行分组像(\d+)-(\d+)这样的表达式会匹配形如666-888的字符串。用圆括号对表达式进行分组有利于以后使用子组的匹配值。要使用子组内的值，只需要\N的方式就能调用。如12re.sub(r'(\d+)-(\d+)','\2\1','666-888')# \2会调用第2个子组里的匹配值，\1会调用第一个子组里的匹配值。输出结果为888-666 Pythonre模块的使用 搜索search()与匹配match()不同点： 搜索search()会在字符串的任意位置搜索匹配的模式。 匹配match()是判断一个字符串能否从起始处全部或者部分的匹配某个模式。 共同点： 二者都会返回一个匹配对象。匹配对象当处理正则表达式时，除了正则表达式对象外，还有另外一种对象类型：匹配对象。这是成功调用match()或search()返回的对象。匹配对象有两个主要的方法：group()和groups()。group()group()要么返回整个匹配对象，要么根据要求返回特定的子组。1234pat = '(\d+)-(\d+)'data = '888-666'print(re.search(pat,data).group()) # 输出888-666,因为此时整个匹配对象是888-666print(re.search(pat,data).group(2)) # 输出666，因为此时group()返回子组2的匹配对象 groups()groups()仅返回一个包含唯一或全部子组的元组，如果没有子组，那么会返回一个空元组。12345678pat1 = '(th\w+).*?and (th\w+).*'pat2 = '(this is (a(pple))) and that is (banana)'pat3 = '\w+'data = 'this is apple and that is banana'print(re.search(pat1,data).groups()) # 输出('this','that')print(re.search(pat2,data).groups()) # 输出('this is apple', 'apple', 'pple', 'banana')print(re.search(pat3,data).groups()) # 输出(),因为没有子组 使用sub()与subn()搜索与替换有两个函数可以实现搜索与替换：sub()与subn()，两个几乎一样，都是将字符串中所有匹配正则表达式的部分进行某种形式的替换，用来替换的部分通常是一个字符串，可也以是一个返回字符串的函数。subn()和sub()一样，但是subn()还返回一个表示替换的总数，替换后的字符串和替换总数一起作为一个拥有两个元素的元组返回。12345678pat1 = 'hello'pat2 = '(hello),(jack)'repl = 'hi'data = 'hello,jack'print(re.sub(pat1,repl,data)) # 输出hi,jackprint(re.subn(pat1,repl,data)) # 输出('hi,jack',1)print(re.sub(pat2,r'\2,\1',data)) # 输出jack,hello(用上面提到的引用子组匹配对象的方法进行替换) 使用split()分隔字符串re模块和正则表达式的对象方法split()对于相对应字符串的工作方式是类似的，但是与分割一个固定字符串相比，它们基于正则表达式的模式分隔字符串，为字符串的分隔功能添加一些额外的威力。如果给定分隔符不是使用特殊符号来匹配多重模式的正则表达式，那么re.split()与str.split()的工作方式相同。如果不想为每次模式的出现都分隔字符串，可以通过为maxsplit参数设定一个值(非0)来指定最大分割数。1234567data = '123:abc:def:456:789'pat = '\d+:'print(re.split(r':',data)) # 输出['123', 'abc', 'def', '456', '789']print(data.split(':')) # 输出['123', 'abc', 'def', '456', '789']print(re.split(pat,data)) # 输出['', 'abc:def:', '789']print(re.split(pat,data,maxsplit=1)) # 输出['', 'abc:def:456:789']]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>读书体会</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫之爬取静态网页（实战篇）]]></title>
    <url>%2F2018%2F02%2F24%2Fpython%E7%88%AC%E8%99%AB%E4%B9%8B%E7%88%AC%E5%8F%96%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5%E5%AE%9E%E6%88%98%E7%AF%87%2F</url>
    <content type="text"><![CDATA[以爬取桌酷网下桌面最新壁纸一栏中的图片为例。本篇教程旨在让新手快速入门爬虫，所以不涉及面向对象编程。12345678910111213141516# encoding:utf-8import requestsfrom bs4 import BeautifulSoupimport osfrom random import choicefrom time import sleepurl = "http://www.zhuoku.com/"header_list = [ "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36", "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50", "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)", "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)"]header1 = &#123;"User-Agent":"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)"&#125;header1 = &#123;"User-Agent":"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)"&#125; 先导入必要的库，配置该项爬虫的基本设置。在header_list中存放几个User-Agent反爬。123456try: r = requests.get(url,headers=header1,timeout=30)except: r = requests.get(url,headers=header1,timeout=30)r.encoding = 'utf-8' 利用requests.get获取桌酷网首页的html文件，并将其设置为utf-8格式。timeout设置为30秒，如果30秒内没有获取成功会报错，为了避免连接超时导致程序停止在except中让程序再次连接这个url12soup = BeautifulSoup(res,"html.parser")all_a = soup.find("div",id="zuixin").find_all('a',attrs=&#123;"class":"title"&#125;) 煮一锅“汤”，解析下载好的html文件。在文件中找到‘zuixin’下所有分类为‘title’的a标签。12345for a in all_a: header = &#123;"User-Agent": choice(header_list)&#125; title = a.get_text().replace("/",'') href = a.get("href") img_url = url + href[1:-4] + "(1).htm"#补第一张图片的全href 值得注意的是，此时我们用choice()函数从上面设置好的header_list列表中随机选择了一个User-Agent作为header里的内容。在下面的每一次requests.get()中都会加上这个header，这样就可以突破很多网站的反爬措施了。遍历找出的每一个a标签,通过get_text()方法取出该标签的元素作为这组图片的title，通过get(‘href’)取出该a标签的href属性内容。通过观察可以发现，这组图片的url就是网站首页url与取出的href属性拼接而成，后面(1).htm这个后缀实际上代表了这组图片的页数。(1).htm既是这组图的第一张图片，(2).htm既是这组图的第二张图片…通过补全url构造出每一组图的第一张图片url。12345678910111213if os.path.isdir(os.path.join("D:\zhuoku",title)): #如果存在文件夹 print("exist" + title) passelse: os.makedirs(os.path.join("D:\zhuoku",title)) #创建文件夹 print("makedir" + title)os.chdir("D:\zhuoku\\" + title) #切换到此文件夹try: img_url_get = requests.get(img_url,headers=header,timeout=30)except: img_url_get = requests.get(img_url,headers=header,timeout=30)sleep(0.5) 判断一下储存图片的文件夹是否存在，不存在就创建一个（os.join()将两个路径拼接起来），然后通过os.chdir()移动到这个文件夹下。还是通过requests.get()获取这张图片页面的html文件。sleep()让程序停止0.5秒，免得访问太频繁给服务器带来太大的负担。设置合适的sleep()时间很重要，既是出于不给网站带来太大压力的道德因素，也是避免访问过于频繁导致服务器强制断开连接使程序中断1234567891011img_url_soup = BeautifulSoup(img_url_get.text,"html.parser")# 找出最大页数max_img_page = img_url_soup.find('div',id="yema").find_all("a")[-1].get_text()for page in range(1,int(max_img_page)+1): jpg_href = url + href[1:-4] + "(" + str(page) + ").htm" + "#turn" try: jpg_href_get = requests.get(jpg_href,headers=header,timeout=30) except: jpg_href_get = requests.get(jpg_href,headers=header,timeout=30) sleep(0.5) 解析下载好的html文件，在html文件中找到这组图片的最大页数。依次构造这组图的每一张图片的url。通过1234jpg_soup = BeautifulSoup(jpg_href_get.text,"html.parser")# 在find()方法后面用方括号将属性括起来可以取出该属性的值jpg_url = jpg_soup.find("div",id="bizhiimg").find("img")["src"] name = jpg_url[-9:] #截取倒数第九位至末尾为图片的名字 依次解析每一张图片的html文件，通过find(‘img’)找出图片所在的img标签并取出src属性的值（类似于get(‘src’)），这个值就是图片URI。12345678910111213141516171819 if os.path.isfile(name): #如果存在名为name的文件 print(name + " exist skip") pass #下面全跳过 else: jpg_header = &#123; "Referer": jpg_href, "User-Agent":choice(header_list) &#125; try: jpg = requests.get(jpg_url,headers=jpg_header,timeout=30) except: jpg = requests.get(jpg_url,headers=header,timeout=30) sleep(0.5) with open(name,'wb') as f: f.write(jpg.content) print(name+" saved")print("congratulations! all finished!") 判断一下图片是否已经保存。如果没有保存通过requests.get()访问刚才找出的URI，此时变量jpg就可以看做是这张图片。以‘wb’形式新建一个名为name变量的值的文件，通过f.write(jpg.content)将图片写入文件中。成功！现在你就有一个完整的爬虫了！启动程序，大概20分钟之后，这些图片就会统统下载到你的电脑里啦~以下是程序的完整代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# encoding:utf-8import requestsfrom bs4 import BeautifulSoupimport osfrom random import choicefrom time import sleepurl = "http://www.zhuoku.com/"header_list = [ "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36", "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50", "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)", "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)"]header1 = &#123;"User-Agent":"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)"&#125;try: r = requests.get(url,headers=header1,timeout=30)except: r = requests.get(url,headers=header1,timeout=30)r.encoding = 'utf-8'soup = BeautifulSoup(r,"html.parser")all_a = soup.find("div",id="zuixin").find_all('a',attrs=&#123;"class":"title"&#125;)for a in all_a: header = &#123;"User-Agent": choice(header_list)&#125; title = a.get_text().replace("/",'') href = a.get("href") img_url = url + href[1:-4] + "(1).htm"#补第一张图片的全href if os.path.isdir(os.path.join("D:\zhuoku",title)): #如果存在文件夹 print("exist" + title) pass else: os.makedirs(os.path.join("D:\zhuoku",title)) #创建文件夹 print("makedir" + title) os.chdir("D:\zhuoku\\" + title) #切换到此文件夹 try: img_url_get = requests.get(img_url,headers=header,timeout=30) except: img_url_get = requests.get(img_url,headers=header,timeout=30) sleep(0.5) img_url_soup = BeautifulSoup(img_url_get.text,"html.parser") max_img_page = img_url_soup.find('div',id="yema").find_all("a")[-1].get_text() for page in range(1,int(max_img_page)+1): jpg_href = url + href[1:-4] + "(" + str(page) + ").htm" + "#turn" try: jpg_href_get = requests.get(jpg_href,headers=header,timeout=30) except: jpg_href_get = requests.get(jpg_href,headers=header,timeout=30) sleep(0.5) jpg_soup = BeautifulSoup(jpg_href_get.text,"html.parser") jpg_url = jpg_soup.find("div",id="bizhiimg").find("img")["src"] #在find方法后面用方括号将属性括起来可以取出该属性的值 name = jpg_url[-9:] #截取倒数第九位至末尾为图片的名字 if os.path.isfile(name): #如果存在名为name的文件 print(name + " exist skip") pass #下面全跳过 else: jpg_header = &#123; "Referer": jpg_href, "User-Agent":choice(header_list) &#125; try: jpg = requests.get(jpg_url,headers=jpg_header,timeout=30) except: jpg = requests.get(jpg_url,headers=header,timeout=30) sleep(0.5) with open(name,'wb') as f: f.write(jpg.content) print(name+" saved")print("congratulations! all finished!")]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python小技巧]]></title>
    <url>%2F2018%2F02%2F07%2Fpython%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[面向对象编程（OOP）方法与函数面向对象编程思想中，方法是指一个对象可以使用的函数，举个例子12arr = [1,2,3]arr.remove(2) arr被定义为指向列表对象的变量，而remove则是list对象的一个方法，用于从列表中删除某个值。而函数则是对对象进行操作，例如12arr = [1,2,3]len(arr) len()函数对其参数求长度。在本例中len()的参数既是一个列表。 一切皆对象python一个很出名的特性是一切皆对象。比如变量，类，甚至函数也可以作为一个对象传给变量。比如：12345678910def plus(x,y): return x+yplus(1,3)from threading import Threatif __name__ == '__main__': t = Threat(target=plus,args=(1,3,)) t.start() t.join() 第八行的target参数传入的是plus函数的对象，此时不需要括号。而第三行的plus()加了括号是告诉python解释器执行这个函数对象。 装饰器当我们想要为某个函数临时添加某个功能时，装饰器能很好地完成这项工作。 装饰器其实就是在函数里定义函数：将目标函数对象传入装饰器里，装饰器内部的函数做一些事情，然后再执行目标函数。1234567891011121314def decorator(func): def wrapper(*args, **kwargs): print('hello') return func(*args, **kwargs) return wrapper@decoratordef test(text): print(text)test('这是关于装饰器的测试')# 输出：# hello# 这是关于装饰器的测试 这里的@是python的语法糖，作用相当于test = decorator(test)，即把目标函数对象传入装饰器中。由于decorator返回的是函数对象wrapper，原来的test便转而指向了wrapper。当我们调用test时，实际上是调用了wrapper。 有时我们需要给装饰器传参，这就麻烦一点，需要多定义层函数：12345678910111213141516def log(context='hello'): def decorator(func): def warpper(*args, **kwargs): print(context) return func(*args, **kwargs) return warpper return decorator@log(context='hi')def test(text): print(text)test('这是关于装饰器的测试')# 输出：# hi# 这是关于装饰器的测试 这里要注意，由于此时的装饰器log有默认参数，所以必须以@log()的形式进行装饰。如果还是用@log，相当于test = log(test)，这就把test赋给了context而decorator缺少位置参数func。而用@log()则使test指向decorator。 常用的内置装饰器python中的装饰器可以对函数进行扩展。 @property@property装饰器可以把类的方法变成属性。例如1234567class Student(): def __init__(self,score): self.score = score#调用Student类qiuyue = Student(90)print(qiuyue.score) #输出结果90 可是这样也不无问题，比如当输入分数不合理（如1000）时，无法对分数进行检查。当然，可以对Student类附加方法实现检查分数。123456789101112131415class Student(): def get_score(self): return self._score def set_score(self,value): if not isinstance(score,int): raise ValueError('score must is an integer!') if value &gt; 100 or value &lt; 0: raise ValueError('score must between 0 to 100!') self._score = value#调用Student类qiuyue = Student()qiuyue.set_score(90)print(qiuyue.get_score()) #输出90 通过set方法对Student的score属性赋值，再用get方法获取score属性。这样就可以实现对score合法性的检查。但是为了一个属性特地写两个方法未免过于繁琐。所以用到装饰器@property封装set方法和get方法，实现对score属性赋值的同时进行数值合法性检查。 12345678910111213141516171819202122232425262728293031class Student(): @property def score(self) return self._score @score.setter def score(self,value) if not isinstance(value,int): raise ValueError('score must is an integer!') if value &gt; 100 or value &lt; 0: raise ValueError('score must between 0 to 100!') self._score = value @property def grade(self): if self._score is None: return None elif self._score &gt;= 90: print('优秀！') elif self._score &gt;=60: print('及格！) else: print('不及格！')#调用Student类qiuyue = Student()qiuyue.score = 90print(qiuyue.score) # 输出90qiuyue.score = 1000 # 报错，ValueErrorqiuyue.grade = '及格' # 报错qiuyue.grade # 输出优秀 可以看到，@property装饰的第一个score，实际上是一个get方法，而@score.setter装饰的第二个score实际上是set方法。@score.setter其实是@property装饰器的副产品。这两个装饰器一个装饰get方法，一个装饰set方法，这样就使score方法变成了Student类的属性，在对score属性赋值（即set方法）时会自动对值的合法性进行检查，调用score属性即调用get方法。@grade.setter并不是必须的，当缺少@grade.setter装饰器时grade属性变成只读属性，无法对其进行赋值，只能读取。 @classmethod与@staticmethod在介绍类方法@classmethod与静态方法staticmethod前，先要清楚一个概念：类属性与实例属性是不同的。12345678class Plus(): num = 1f = Plus()f.num = 2print(Plus.num) # 结果为2 print(f.num) # 结果为1 众所周知，要调用类的方法，我们首先要把这个类实例化，然后通过实例名.方法名的方式调用。而@classmethod与@staticmethod都可以实现通过类名.方法名的方式调用方法。 @classmethod当类中有些方法不需要涉及实例，而需要涉及类，如对类属性的修改，往往使用@classmethod。用@classmethod修饰的方法不会将实例传入方法中，而会自动将自身类作为第一个参数传入。所以这个方法不需要写self参数，但需要一个cls参数代表这个类。1234567class Apple(): species = '富士苹果' @classmethod def clsmed(cls): print('苹果的种类为：%s' % cls.species)Apple.clsmed() # 输出：苹果的种类为：富士苹果 @staticmethod如果类中有些方法既不涉及类，也不涉及实例，可以用@staticmethod。@staticmethod既不会将实例传入方法，也不会将自身类传入方法。所以既没有self参数也没有cls参数。12345678910111213class Apple(): apple = 1 def change(self,data): self.apple = data print('还有%s个苹果' % self.apple) @staticmethod def stamed(): print('没有苹果了')apple = Apple()apple.change(2) # 输出：还有2个苹果Apple.stamed() # 输出： 没有苹果了 下面这个例子加深区分：1234567891011121314151617181920class Apple(): species = '富士苹果' def __init__(self,data): self.num = data def common(self): print('还有%s个苹果' % self.num) @classmethod def clsmed(cls): print('苹果的种类为：%s' % cls.num) @staticmethod def stamed(): print('没有苹果了')apple = Apple(2)apple.common() # 输出：还有2个苹果Apple.clsmed() # 输出：苹果的种类为：富士苹果Apple.stamed() # 输出：没有苹果了 @wraps(func)函数的__name__方法可以取出函数名，看一个装饰器的例子：123456789101112def decorator(func): def wrapper(*args, **kwargs): print('hello') return func(*args, **kwargs) return wrapper@decoratordef test(): print('hi')print(test.__name__)# 输出：wrapper 可以看到，test的__name__属性被改变了，因为返回的那个wrapper()函数名字就是wrapper，所以，需要把原始函数的__name__等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错。用functools.wraps可以解决这个问题：1234567891011121314from functools import wrapsdef decorator(func): @wraps(func) def wrapper(*args, **kwargs): print('hello') return func(*args, **kwargs) return wrapper@decoratordef test(): print('hi')print(test.__name__)# 输出： test Python的特点像java，C#这种编译型语言，会将代码编译成二进制再运行。而python作为一种解释型语言，是动态的逐行解释代码的，也就是从脚本第一行开始，没有统一的入口。一个Python源码文件除了可以被直接执行外，还可以作为模块（也就是库）被其他.py文件导入。此时这个源码文件的文件名（不包括.py）就是库名。python本身有很多有趣的方法，会在每一个python文件里自动生成，在特殊情况下还会自动调用，这种方法称之为魔法方法。魔法方法的形式为两个下划线(__)+方法名+两个下划线(__)。如：__new__。下面介绍一些常见的魔法方法。 __file__通过下面一行代码，就能很直接地看出__file__的作用。123# 文件位置为E:/python/test.pyprint(__file__)# 输出E:/python/test.py 可见，__file__代表了当前python文件的路径。而且如前面所言，这个方法是python自动实现的，不需要你去编写。 __name__相信不少python初学者都见到过这样一段代码：12if __name__ == "__main__": app.run() 可能很多人第一次看到这段代码的时候都会困惑：这个__main__我理解，是主函数的意思，可是这__name__是个什么东东？老规矩，上一段代码:123# 文件位置为E:/python/test.pyprint(__name__)# 输出__main__ java，C等语言都会显示地定义一个main()函数，一个用C编写的程序都是以main()作为程序入口的。而python不同，哪个文件被直接执行，哪个文件的模块名就是__main__。现在说回__name__, __name__存放的就是当前python文件的名字，那么现在情况就很明显了，开头那段代码的意思是：如果这个文件是被直接运行的，就执行app.run()，如果这个文件是被别的文件导入后运行的，就会跳过app.run()。这样做的好处是避免了一些只能在主程序里执行的代码由于被导入了其他文件而错误执行。 requirements.txt在查看别人的python项目时，常会见到一个requirements.txt文件，主要是说明这个项目依赖的模块及其版本，这样别人使用我们的项目时可以快速安装所需模块。我们可以用这个命令生成requirements.txt文件：1pip freeze &gt; requirements.txt 要导入这个文件里的模块也很简单，只要用:1pip install -r requirements.txt is与==的区别写代码的时候常常用is和==来比较两个对象是否相等，但是它们有什么不同呢？参考下面的例子：12345678910111213141516171819a = 1b = 1a == b # Truea is b # Truea = 888b = 888a == b # Truea is b # Falsea = 'hello'b = 'hello'a is b # Truea == b # Truea = 'hello world'b = 'hello world'a == b # Truea is b # False 奇怪真奇怪！is和==的结果不同！不是说好的都是比较两个对象是否相等吗？怎么到这里变了样了？不急，先介绍一下python内置的一个函数：id()，这个函数会打印参数的内存地址，让我们来试试：123456789a = 888b = 888id(a) # 1939743592336id(b) # 1939745557808a = 'hello world'b = 'hello world'id(a) # 1939745897200id(b) # 1939745912624 可以看到，尽管a、b的值是相同的，但是其内存地址却不同。那么答案就很显然了，is比较的是两个对象的内存地址是否相等，==比较的是两个对象的值是否相等。这样就能解释为什么is和==的结果不同了。But wait，那么为什么当a、b的值为1和’hello’时，is与==的结果是一样的呢？这就要说到python的小整数池和垃圾回收机制了。python为了让运行速度快些，在内存中专门开辟了一块区域放置0到256，所有代表0到256的对象都会指向这个区域。类似的，python为短文本也开辟了这样的一块内存空间。所以这时is和==会得到相同的结果：123456789a = 1b = 1id(a) # 1963327952id(b) # 1963327952a = 'hello' b = 'hello' id(a) # 1939745887600id(b) # 1939745887600 对象、值和别名先来看一段代码：12345b = [1, 2, 3]a = bprint(a is b) # Trueb.append(4)print(a) # [1, 2, 3, 4] a is b返回True，说明这python内部a与b是相同的，变量a与变量b都指向同一个对象。此时称a和b为这个对象的别名。当对象的值发生改变时，a和b自然也会随之改变。如果a、b只是值相等而不指向同一个对象，我们称a与b是相等的。相同必定相等，相等不一定相同。123a = [1, 2, 3]b = [1, 2, 3]print(a is b) # False 全局变量在函数之外创建的变量属于main，有被称为全局变量。它们可以在main中的任意函数中访问，与局部变量在函数结束时消失不同，全局变量可以在不同函数的调用之间持久存在。 全局变量常常用作标志（Flags）。标志是一种布尔型变量，可以标志一个条件是否为真。1234567verbose = Truedef example(): if verbose: print('你好，今天天气很好！') else: print('你好') 如果在函数里尝试给全局变量赋值，必须先用global关键字进行声明，否则函数会创建一个同名局部变量而不是使用全局变量。123456verbose = Truedef example(): global verbose verbose = False print('你好') 封装协议常常可以看到封装协议这个词，比如smtplib.SMTP类就封装了smtp协议，Flask-httpauth.HTTPBasicAuth类封装了http协议。 所谓某个包封装了某个协议的意思是包为这个协议提供了一系列接口，使用者只需要调用这些接口就会自动实现这些协议,这样我们就不用自己再去造轮子了。 下面这段代码就是一个例子，我们调用SMTP类的connect()方法连接QQ邮箱服务器，starttls()方法实现smtp协议的tls连接，login()方法实现与服务器连接。1234567from smtplib import SMTPsmtp = SMTP()smtp.connect(host='smtp.qq.com', port=587)smtp.ehlo()smtp.starttls()smtp.ehlo()smtp.login('xxxxx@qq.com', 'passwd') 可以看到，我们只是调用了一系列接口就自动遵循smtp协议与QQ邮箱服务器连接上了，至于方法内部是如何实现的我们并不需要了解。 GILGIL全称Global Interpreter Lock。Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行，换言之，对于某个特定时刻，一个进程里只有一个线程在运行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。 GIL锁的存在导致python不能很好地利用多核性能，但是可以通过多进程实现多任务。不同进程之间的GIL互不影响。 字符串拼接用join()方法可以把字符串插入到迭代对象中。相当于split()的逆操作：123&gt;&gt;&gt; l = ['hello', ' ', 'world']&gt;&gt;&gt; ''.join(l) # 'hello world'&gt;&gt;&gt; '-'.join(l) # hello- - world 索引迭代通常我们想要找出迭代对象中某个值的索引，比如找出列表中第一个重复字符的索引，我们会这样做：123456789l = ['a', 'b', 'c', 'a', 'b']visited = dict()def find(l): for i in range(len(l)): if l[i] in visited.keys(): return i visited[l[i]] = 1 return None 这种方法虽然可行，但是未免太蠢了。又是range()又是len()的，一点不简洁。enumerate()可以把一个迭代对象变成索引-元素树。（enumerate： 枚举，列举）123456789l = ['a', 'b', 'c', 'c', 'b']visited = &#123;&#125;def find(l): for i, v in enumerate(l): if v in visited.keys(): return i visited[v] = 1 return None 这样就变得干净清爽多了。 合并Python提供了很多合并的方法：12345678910111213141516171819202122232425"""合并两个列表"""l1 = ['a', 'b', 'c']l2 = ['d', 'f', 'g']# + 操作，不会改变原来的列表l3 = l1 + l2 # ['a', 'b', 'c', 'd', 'f', 'g']# extend()方法l2.extend(l1) # l2变成['d', 'f', 'g', 'a', 'b', 'c']，l1不变# ** 操作,不会改变原来的列表l3 = [**l2, **l1] # ['d', 'f', 'g', 'a', 'b', 'c']"""合并两个字典"""d1 = &#123;'a': 1, 'b':2&#125;d2 = &#123;'d': 3, 'g': 4&#125;# ** 操作d3 = &#123;**d2, **d1&#125; # &#123;'a': 1, 'd': 3, 'b': 2, 'g': 4&#125;, 如果有重复键，则以第一个参数为准# update()方法d1.update(d2) # d1变成&#123;'d': 3, 'b': 2, 'a': 1, 'g': 4&#125;，d2不变# * 操作，取两字典key值的集合d3 = &#123;*d2, *d1&#125; # &#123;'d', 'a', 'b', 'g'&#125; 对数值做格式化输出用format()方法可以实现字符串格式化。1'hello &#123;&#125;'.format('Mike') # 'hello Mike' 除此之外，format()还有很多有趣的用法： 格式限定符为了限定输出格式，需要在{}里加上: 填充与对齐&gt;、&lt;、^表示右对齐，左对齐，居中。后面带宽度 :后面带填充的字符。默认是空格1234'there are &#123;:&gt;3&#125; apples in here'.format(5) # 'there are 5 apples in here''there are &#123;:&lt;3&#125; apples in here'.format(5) # 'there are 5 apples in here''there are &#123;:^3&#125; apples in here'.format(5) # 'there are 5 apples in here''there are &#123;:0&gt;3&#125; apples in here'.format(5) # 'there are 005 apples in here' 控制精度输出浮点数时常常要控制精度：1'圆周率约等于&#123;:.2f&#125;'.format(3.1415926) # '圆周率约等于3.14' 其中2表示保留到小数点后两位，遵循4舍5入原则。f表示数据是浮点数。 也可以控制整体的位数：12'圆周率约等于&#123;:.2&#125;'.format(3.1415926) # '圆周率约等于3.1''圆周率约等于&#123;:.4&#125;'.format(3.1415926) # '圆周率约等于3.142' 除了format()之外，还可以用传统的占位符对输出进行格式化：123'圆周率约等于%.2f' % (3.1415) # '圆周率约等于3.14''圆周率约等于%8.2f' % (3.141) # '圆周率约等于 3.14''圆周率约等于%08.2f' % (3.141) # '圆周率约等于00003.14' 随机选择我们想从序列中随机挑选出元素，或者想生成随机数。可以使用random模块 从序列中随机选择从序列中随机挑选元素,可用random.choice()函数：1234567import randomvalues = [1, 2, 3, 4, 5, 6]random.choice(values) # 2random.choice(values) # 5random.choice(values, 2) # [1, 4]random.choice(values, 3) # [3, 2, 6] 产生随机整数用random.randint()函数，random.randint()是前闭后闭的：12random.randint(1, 10) # 5random.randint(0, 15) # 15 产生0到1之间的浮点数用random.random()函数，返回值是一个16位小数12randon.randon() # 0.2101003475395049random.randon() # 0.16454716916733036]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程与线程]]></title>
    <url>%2F2018%2F01%2F09%2F%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[什么是进程/线程众所周知，CPU是计算机的核心，它承担了所有的计算任务。而操作系统是计算机的管理者，是一个大管家，它负责任务的调度，资源的分配和管理，统领整个计算机硬件。应用应用程序是具有某种功能的程序，程序运行与操作系统之上。 进程进程时一个具有一定功能的程序在一个数据集上的一次动态执行过程。进程由程序，数据集合和进程控制块三部分组成。程序用于描述进程要完成的功能，是控制进程执行的指令集；数据集合是程序在执行时需要的数据和工作区；程序控制块（PCB）包含程序的描述信息和控制信息，是进程存在的唯一标志。 线程在很早的时候计算机并没有线程这个概念，但是随着时代的发展，只用进程来处理程序出现很多的不足。如当一个进程堵塞时，整个程序会停止在堵塞处，并且如果频繁的切换进程，会浪费系统资源。所以线程出现了。线程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。一个进程可以拥有多个线程，而且属于同一个进程的多个线程间会共享该进行的资源。 进程与线程的区别 一个进程由一个或者多个线程组成，线程是一个进程中代码的不同执行路线。 切换进程需要的资源比切换线程的要多的多。 进程之间相互独立，而同一个进程下的线程共享程序的内存空间（如代码段，数据集，堆栈等）。某进程内的线程在其他进程不可见。换言之，线程共享同一片内存空间，而进程各有独立的内存空间。以下是作者在知乎上看到的关于进程与线程的讨论，其中一个作者感觉很有道理，摘抄如下： 作者：zhonyong链接：https://www.zhihu.com/question/25532384/answer/81152571 首先来一句概括的总论：进程和线程都是一个时间段的描述，是CPU工作时间段的描述。下面细说背景：CPU+RAM+各种资源（比如显卡，光驱，键盘，GPS, 等等外设）构成我们的电脑，但是电脑的运行，实际就是CPU和相关寄存器以及RAM之间的事情。一个最最基础的事实：CPU太快，太快，太快了，寄存器仅仅能够追的上他的脚步，RAM和别的挂在各总线上的设备完全是望其项背。那当多个任务要执行的时候怎么办呢？轮流着来?或者谁优先级高谁来？不管怎么样的策略，一句话就是在CPU看来就是轮流着来。一个必须知道的事实：执行一段程序代码，实现一个功能的过程介绍 ，当得到CPU的时候，相关的资源必须也已经就位，就是显卡啊，GPS啊什么的必须就位，然后CPU开始执行。这里除了CPU以外所有的就构成了这个程序的执行环境，也就是我们所定义的程序上下文。当这个程序执行完了，或者分配给他的CPU执行时间用完了，那它就要被切换出去，等待下一次CPU的临幸。在被切换出去的最后一步工作就是保存程序上下文，因为这个是下次他被CPU临幸的运行环境，必须保存。串联起来的事实：前面讲过在CPU看来所有的任务都是一个一个的轮流执行的，具体的轮流方法就是：先加载程序A的上下文，然后开始执行A，保存程序A的上下文，调入下一个要执行的程序B的程序上下文，然后开始执行B,保存程序B的上下文。。。。========= 重要的东西出现了========进程和线程就是这样的背景出来的，两个名词不过是对应的CPU时间段的描述，名词就是这样的功能。进程就是包换上下文切换的程序执行时间总和 = CPU加载上下文+CPU执行+CPU保存上下文线程是什么呢？进程的颗粒度太大，每次都要有上下的调入，保存，调出。如果我们把进程比喻为一个运行在电脑上的软件，那么一个软件的执行不可能是一条逻辑执行的，必定有多个分支和多个程序段，就好比要实现程序A，实际分成 a，b，c等多个块组合而成。那么这里具体的执行就可能变成：程序A得到CPU =》CPU加载上下文，开始执行程序A的a小段，然后执行A的b小段，然后再执行A的c小段，最后CPU保存A的上下文。这里a，b，c的执行是共享了A的上下文，CPU在执行的时候没有进行上下文切换的。这里的a，b，c就是线程，也就是说线程是共享了进程的上下文环境，的更为细小的CPU时间段。到此全文结束，再一个总结：进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同。 开进程需要时间学习《python爬虫开发与项目实践》时，执行下面一段代码：1234567891011121314from multiprocessing import Processimport osdef run_process(name): print("Child process %s (%s) is running" % (name,os.getpid()))if __name__ == "__main__": print("parant process %s " % os.getpid()) for i in range(5): p = Process(target=run_process, args=(str(i),)) print("process will start") p.start() p.join() print("process end") 显示的结果是123456789101112parant process 6332 process will startprocess will startprocess will startprocess will startprocess will startChild process 2 (9896) is runningChild process 0 (11208) is runningChild process 3 (5464) is runningChild process 1 (10208) is runningChild process 4 (12596) is runningprocess end 可以看到，程序在执行完1print (&quot;parant process %s &quot; % os.getpid()) 没有接着马上执行run_process()，而是先打印process will start，最后把子进程一起执行。这是因为子进程的创建是需要时间的，在这个空闲时间里父进程继续执行代码，而子进程在创建完成后显示。 Pool进程池需要创建多个进程时，可以使用multiprocessing中的Pool类开进程池。Pool()默认开启数量等于当前cpu核心数的子进程（当然可以手动改变）1234567891011121314from multiprocessing import Pooldef hello(i): print("hello ,this is the %d process" % i)def main(): p = Pool() for i in range(1,5): p.apply_async(target=hell0,args=(i,)) p.close p.joinif __name__ == "__main__": main() apply_async表示在开进程时不阻塞主进程，是异步IO的一种方式之一。targe参数传入要在子线程中执行的函数对象，args以元组的方式传入函数的参数。join会等待线程池中的每一个线程执行完毕，在调用join之前必须要先调用close，close表示不能再向线程池中添加新的process了。 进程间的通信每个进程各自有不同的用户地址空间,任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核,在内核中开辟一块缓冲区,进程A把数据从用户空间拷到内核缓冲区,进程B再从内核缓冲区把数据读走,内核提供的这种机制称为进程间通信。假如创建了多个进程，那么进程间的通信是必不可少的。Python提供了多种进程通信的方式，其中以Queue和Pipe用得最多。下面分别介绍这两种模式。 QueueQueue是一种多进程安全的队列。实现多进程间的通信有两种方法： get() 用于向队列中加入数据。有两个属性：blocked和timeout。blocked为true时（默认为True）且timeout为正值时，如果当队列已满会阻塞timeout时间，在这个时间内如果队列有空位会加入，如果超过时间仍然没有空位会抛出Queue.Full异常。 put() 用于从队列中获取一个数据并将其从队列中删除。有两个属性：blocked和timeout。blocked为true（默认为True）且timeout为正值时，如果当前队列为空会阻塞timeout时间，在这个时间内如果队列有新数据会获取，如果超过时间仍然没有新数据会抛出Queue.Empty异常。1234567891011121314151617181920212223242526from multiprocessing import Process,Queueimport osdef put_data(q,nums): print('现在的进程编号为：%s，这是一个put进程' % os.getpid()) for num in nums: q.put(num) print('%d已经放入队列中啦！' % num)def get_data(q): print('现在的进程编号为：%s，这是一个get进程' % os.getpid()) while True: print('已经从队列中获取%s并从中删除' % q.get())if __name__ == '__main__': q = Queue() p1 = Process(target=put_data,args=(q,['1','2','3'],)) p2 = Process(target=put_data,args=(q,['4','5','6'],)) p3 = Process(target=get_data,args=(q,)) p1.start() p2.start() p3.start() p1.join() p2.join() # p3是个死循环，需要手动结束这个进程 p3.terminate() 我们来看一下运行结果：123456789101112131415现在的进程编号为：10336，这是一个put进程1已经放入队列中啦！2已经放入队列中啦！3已经放入队列中啦！现在的进程编号为：9116，这是一个get进程已经从队列中获取1,并从中删除已经从队列中获取2并从中删除已经从队列中获取3并从中删除现在的进程编号为：2732，这是一个put进程4已经放入队列中啦！5已经放入队列中啦！已经从队列中获取4,并从中删除6已经放入队列中啦！已经从队列中获取5并从中删除已经从队列中获取6并从中删除 PipePipe与Queue不同之处在于Pipe是用于两个进程之间的通信。就像进程位于一根水管的两端。让我们看看Pipe官方文档的描述： Returns a pair (conn1, conn2) of Connection objects representing the ends of a pipe. Piep返回conn1和conn2代表水管的两端。Pipe还有一个参数duplex（adj. 二倍的，双重的 n. 双工；占两层楼的公寓套房），默认为True。当duplex为True时，开启双工模式，此时水管的两边都可以进行收发。当duplex为False，那么conn1只负责接受信息，conn2只负责发送信息。conn通过send()和recv()来发送和接受信息。值得注意的是，如果管道中没有信息可接受，recv()会一直阻塞直到管道关闭（任意一端进程接结束则管道关闭）。123456789101112131415161718192021222324from multiprocessing import Process,Pipeimport osdef put_data(p,nums): print('现在的进程编号为：%s，这个一个send进程' % os.getpid()) for num in nums: p.send(num) print('%s已经放入管道中啦！' % num)def get_data(p): print('现在的进程编号为：%s，这个一个recv进程' % os.getpid()) while True: print('已经从管道中获取%s并从中删除' % p.recv())if __name__ == '__main__': p = Pipe(duplex=False) # 此时Pipe[1]即是Pipe返回的conn2 p1 = Process(target=put_data,args=(p[1],['1','2','3'],)) # 此时Pipe[0]即是Pipe返回的conn1 p3 = Process(target=get_data,args=(p[0],)) p1.start() p3.start() p1.join() p3.terminate() 让我们看一下输出结果12345678现在的进程编号为：9868，这个一个recv进程现在的进程编号为：9072，这个一个send进程1已经放入管道中啦！已经从管道中获取1,并从中删除2已经放入管道中啦！已经从管道中获取2并从中删除3已经放入管道中啦！已经从管道中获取3并从中删除 控制线程我们是没有办法完全人为控制线程的，因为线程由系统控制。但是可以用一些方式来影响线程的调用，比如互斥锁，sleep（阻塞），死锁等。 线程的几种状态新建—–就绪——————运行—–死亡&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;等待（阻塞）线程的生命周期由run方法决定，当run方法结束时线程死亡。可以通过继承Thread，重写run方法改变Thread的功能，最后还是通过start()方法开线程。123456789101112131415161718192021from threading import Threadclass MyThread(Thread): def run(self): print('i am sorry')if __name__ == '__main__': t = MyThread() t.start()``` 通过args参数以一个元组的方式给线程中的函数传参。 ```pythonfrom threading import Threaddef sorry(name): print('i am sorry',name)if __name__ == '__main__': t = Thread(target=sorry,args=('mike')) t.start() 线程锁多线程中任务中，可能会发生多个线程同时对一个公共资源（如全局变量）进行操作的情况，这是就会发生混乱。为了避免这种情况，需要引入线程锁的概念。只有一个线程能处于上锁状态，当一个线程上锁之后，如果有另外一个线程试图获得锁，该线程就会挂起直到拥有锁的线程将锁释放。这样就保证了同时只有一个线程对公共资源进行访问或修改。12345678910111213141516171819from threading import Thread,Locknum = 0def puls(): # 获得一个锁 lock = Lock() global num # acquire()方法上锁 lock.acquire() num += 1 print(num) # release()方法解锁 lock.release()if __name__ == '__main__': for i in range(5): t = Thread(target=plus) t.start() t.join() join()方法会阻塞主线程直到子线程全部结束（也就是同步）。 锁的用处: 确保某段关键代码只能由一个线程从头到尾执行，保证了数据的唯一性。 锁的坏处: 阻止了多线程并发执行，效率大大降低。 由于存在多个锁，不同的线程持有不同的锁并试图获取对方的锁时，可能造成死锁。 守护线程线程其实并没有主次的概念，我们一般说的‘主线程’实际上是main函数的线程，而所谓主线程结束子线程也会结束是因为在主线程结束时调用了系统的退出函数。而守护线程是指‘不重要线程’。主线程会等所有‘重要’线程结束后才结束。通常当客户端访问服务器时会为这次访问开启一个守护线程。将setDaemon属性设为True即可将该线程设为守护线程。123456789101112from threading import Threadn = 100def count(x,y): return n=x+yif __name__ == '__main__': t = Thread(target=count,args=(1,2)) t.setDaemon = True # ...]]></content>
      <categories>
        <category>Web开发</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http学习]]></title>
    <url>%2F2017%2F12%2F17%2Fhttp%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[TCP/IP与DNS什么是TCP/IP?协议中存在各式各样的内容。从电缆的规格到 IP 地址的选定方法、寻找异地用户的方法、双方建立通信的顺序，以及 Web 页面显示需要处理的步骤，等等。像这样把与互联网相关联的协议集合起来总称为 TCP/IP。HTTP 属于它内部的一个子集。也有说法认为，TCP/IP 是指 TCP 和 IP 这两种协议。还有一种说法认为，TCP/IP 是在 IP 协议的通信过程中，使用到的协议族的统称。 IPIP与IP地址不同。IP是一种网络协议，它的作用是把数据包传给对方。具体是通过MAC地址和ip地址来实现的。MAC地址对应网卡所属的固定地址，ip地址指节点被分配到的地址。IP地址可以与MAC地址对应，IP地址可以换，MAC地址一般是固定的。IP 间的通信依赖 MAC 地址。在网络上，通信的双方在同一局域网（LAN）内的情况是很少的，通常是经过多台计算机和网络设备中转才能连接到对方。而在进行中转时，会利用下一站中转设备的 MAC 地址来搜索下一个中转目标。这时，会采用 ARP 协议（AddressResolution Protocol）。ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC 地址。 TCP所谓的字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。而可靠的传输服务是指，能够把数据准确可靠地传给对方。一言以蔽之，TCP 协议为了更容易传送大数据才把数据分割，而且 TCP 协议能够确认数据最终是否送达到对方。 TCP的三次握手TCP把数据包发出去之后还会确认数据到达了目的地，通过三次握手机制进行确认。发送端发送数据时，TCP会向服务器发送带有SYN标记的数据包，当服务器接收到这个数据包后，会返回一个带有SYN或者ASK的数据包表示确认，最后发送端会再次发送带有ASK标志的数据包表示握手结束。 DNSDNS（Domain Name System）服务是和 HTTP 协议一样位于应用层的协议。它提供域名到 IP 地址之间的解析服务。计算机既可以被赋予 IP 地址，也可以被赋予主机名和域名。比如 www.baidu.com。用户通常使用主机名或域名来访问对方的计算机，而不是直接通过 IP 地址访问。因为与 IP 地址的一组纯数字相比，用字母配合数字的表示形式来指定计算机名更符合人类的记忆习惯。但要让计算机去理解名称，相对而言就变得困难了。因为计算机更擅长处理一长串数字。为了解决上述的问题，DNS 服务应运而生。DNS 协议提供通过域名查找 IP 地址，或逆向从 IP 地址反查域名的服务。 综上，从输入网址到服务器获得请求的过程是： HTTP客户端与服务器之间通过TCP/IP等协议进行HTTP报文的传输。HTTP报文又分为请求报文（客户端发送至服务器）和响应报文（服务器发送至客户端）。无论是哪种报文，其格式都是大同小异的。下面进行通过《图解HTTP》上的一张图片进行简单介绍上图分别是一个请求报文和一个响应报文。请求报文又分成两部分：请求头（GET/HTTP/1.1）和请求首部（XXXX:XXXX）。get是一种请求方法，表示请求从服务器获得信息，除此之外还有post方法（从服务器获得信息的同时向服务器传递一些信息），put方法（向服务器传递信息），delect方法（从服务器删除信息）等。HTTP/1.1表示该请求使用的是1.1版本的HTTP协议。而首部字段则包含了本次请求的有关信息，如Host表示本次请求的主机地址，User-Agent表示发出请求的浏览器内核信息，Accept-luangage表示浏览器接受的语言等。响应报文的响应头是HTTP/1.1 200 OK。200是一种状态码，表示成功，4xx表示客户端错误，5xx表示服务器错误，3xx表示重定向。响应首部字段内容与请求首部作业相同，报文主体里则包含了本次响应的具体信息，通常是HTML文档。]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新开始]]></title>
    <url>%2F2017%2F12%2F02%2F%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[前阵子手贱删了博客文件，还糊里糊涂地把coding里的项目也删了。然后各种蜜汁错误，各种无法重新部署。最近几天又蜜汁部署成功。可以说十分难受了。 不过塞翁失马，焉知非福。经过这么一遭我再次练习了一遍coding+hexo下博客的部署，也算是好事一桩了吧？（强行自我安慰一波233）以后我一定天天向上，重新做人，再不手贱。 再次感谢王哥的教程，很详细，帮助很大，很好，很棒。感兴趣的同志可以去他那里转转呀（手动滑稽）windliang的博客扯到这里算是暂时结束，以后有时间再上来扯扯淡，写点学习心得啥的吧。]]></content>
      <categories>
        <category>心得</category>
      </categories>
      <tags>
        <tag>闲聊</tag>
      </tags>
  </entry>
</search>
